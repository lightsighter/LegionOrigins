\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}

\newcommand{\oton}[1]{{#1}_1,\ldots,{#1}_n}
\newcommand{\otok}[2]{{#2}_1,\ldots,{#2}_{#1}}
\newcommand{\dplus}{\text{+\!+}}
\newcommand{\llbracket}{[\![}
\newcommand{\rrbracket}{]\!]}
\makeatletter
\newcommand{\nonint}[1][]{\#\@ifmtarg{#1}{}{_{\!\!#1}}}
\makeatother

% fun latex tricks to make typeenv and opsenv more friendly
\makeatletter
\define@key{typeenv}{G}{\def\typeenv@G{#1}}
\define@key{typeenv}{P}{\def\typeenv@P{#1}}
\define@key{typeenv}{O}{\def\typeenv@O{#1}}
\newcommand{\typeenvx}[1][]{
{
% default values
\def\typeenv@G{\Gamma}
\def\typeenv@P{\Phi}
\def\typeenv@O{\Omega}
\setkeys{typeenv}{#1}
\typeenv@G, \typeenv@P, \typeenv@O \vdash \,
}}
\newcommand{\typeenv}[3][]{\typeenvx[#1] {#2} : {#3}}
\define@key{opsenv}{M}{\def\opsenv@M{#1}}
\define@key{opsenv}{L}{\def\opsenv@L{#1}}
\define@key{opsenv}{H}{\def\opsenv@H{#1}}
\define@key{opsenv}{S}{\def\opsenv@S{#1}}
\define@key{opsenv}{C}{\def\opsenv@C{#1}}
\newcommand{\opsenvx}[1][]{
{
% default values
\def\opsenv@M{M}
\def\opsenv@L{L}
\def\opsenv@H{H}
\def\opsenv@S{S}
\def\opsenv@C{C}
\setkeys{opsenv}{#1}
\opsenv@M, \opsenv@L, \opsenv@H, \opsenv@S, \opsenv@C \vdash \,
}}
\newcommand{\opsenv}[4][]{\opsenvx[#1] {#2} \mapsto {#3}, {#4}}
\makeatother

\begin{figure*}
\centering
{\small
\begin{tabular}{cclr}

$T$ & ::= &  & types \\
  &$\mid$& bool $\;\;\;\mid\;\;\;$ int & base types \\
  &$\mid$& $\langle T_1, T_2 \rangle$ & tuple \\
  &$\mid$& $T@(\oton{r})$ & pointer \\
  &$\mid$& $\text{coloring}(r)$ & region coloring \\
  &$\mid$& $\exists \oton{r}. T\text{ where }\Omega$ & region relationship \\
  &$\mid$& $\forall \oton{r}. (\oton{T}), \Phi, Q \rightarrow T_r$ & functions \\
\\
$\Omega$ & ::= & $\{ \oton{\omega} \}$ & region constraints \\
$\omega$ & ::= & $r_1 \leq r_2$ & subregion \\
  &$\mid$& $r_1 * r_2$ & disjointness \\
\\
$\Phi$ & ::= & $\{ \oton{\phi} \}$ & privileges \\
$\phi$ & ::= & reads$(r)$ $\;\;\;\mid\;\;\;$ writes$(r)$ $\;\;\;\mid\;\;\;$ $\text{reduces}_{id}(r)$ & \\
\\
$Q$ & ::= & $\{ \oton{q} \}$ & coherence modes \\
$q$ & ::= & atomic$(r)$ $\;\;\;\mid\;\;\;$ simult$(r)$ & \\
\\
$v$ & ::= & & values \\
  &$\mid$& $bv$ $\;\;\;\mid\;\;\;$ $iv$ & base values \\
  &$\mid$& $\langle v_1, v_2 \rangle$ & tuple \\
  &$\mid$& null $\;\;\;\mid\;\;\;$ $a$ & address \\
  &$\mid$& $\{ (a_i, iv), \ldots \}$ & coloring \\
  &$\mid$& $\langle \langle \oton{\rho}, v\rangle \rangle$ & region relationship instance \\
\\
$bv$ & ::= & false $\;\;\;\mid\;\;\;$ true \\
\\
$iv$ & ::= & 0 $\;\;\;\mid\;\;\;$ 1 $\ldots$ \\
\\
$e$ & ::= & & expressions \\
  &$\mid$& $bv$ $\;\;\;\mid\;\;\;$ $iv$ & constants \\
  &$\mid$& $\langle e_1, e_2 \rangle$ $\;\;\;\mid\;\;\;$ $e$.1 $\;\;\;\mid\;\;\;$ $e$.2 & tuple \\
  &$\mid$& $id$ &  \\
  &$\mid$& $\text{new}\ T@r$ $\;\;\;\mid\;\;\;$ $\text{null }T@r$ $\;\;\;\mid\;\;\;$ $\text{isnull}(e)$ & \\
  &$\mid$& $\text{upregion}(e, r_1,\ldots,r_n)$ $\;\;\;\mid\;\;\;$ $\text{downregion}(e, r_1,\ldots,r_n)$ & \\
  &$\mid$& $\text{read}(e_1)$ $\;\;\;\mid\;\;\;$ $\text{write}(e_1, e_2)$ $\;\;\;\mid\;\;\;$ $\text{reduce}(id, e_1, e_2)$ & memory access \\
  &$\mid$& $\text{newcolor}\ r$ $\;\;\;\mid\;\;\;$ $\text{color}(e_1, e_2, e_3)$ & coloring operations \\
  &$\mid$& $e_1 + e_2$ & integer operations \\
  &$\mid$& $e_1 < e_2$ & comparison operations \\
  &$\mid$& $\text{let}\ id : T = e_1 \text{in}\ e_2$ &  \\
  &$\mid$& $\text{if}\ e_1\ \text{then}\ e_2\ \text{else}\ e_3$ &  \\
  &$\mid$& $id[r_1, \ldots, r_n](e_1,\ldots,e_n)$ & task calls \\
  &$\mid$& $\text{partition}\ r_p\text{ using }e_1\text{ as }\oton{r}\text{ in }\ e_2$ &  \\
  &$\mid$& $\text{pack}\ e_1\ \text{as}\ T[r_1,\ldots,r_n]$ &  \\
  &$\mid$& $\text{unpack}\ e_1\ \text{as}\ id : T[r_1,\ldots,r_n]\ \text{in}\ e_2$ &  \\

\end{tabular}
}
\caption{Legion Core Language}
\label{fig:langdef}
\end{figure*}

%\newcommand{\infrule}[2]{\displaystyle\frac{\displaystyle\strut{#1}}{\displaystyle\strut {#2}}}
\newcommand{\cinfrule}[3]{\parbox{14cm}{\hfil$\infrule{#1}{#2}$\hfil}\parbox{4cm}{$\,#3$\hfil}}
\newcommand{\finfrule}[2]{\framebox{$\infrule{#1}{#2}$}}
\newcommand{\oldfinfrule}[2]{\vspace{10pt}\framebox{$\infrule{#1}{#2}$}\vspace{10pt}}

\newcommand{\infx}[2]{\infrule{\begin{array}{l}{#1}\end{array}}{#2}}

\pagebreak

\section{Legion Core Language}
\label{sec:legioncore}

\subsection{Language Definition}
\label{subsec:langdef}

Figure~\ref{fig:langdef} defines the core subset of Legion application language.
Legion includes basic boolean, integer and tuple types.  Pointers are included as well, but in
addition to specifying the type of value it points to, a pointer's type also constrains where in
memory it can point (i.e. only into regions listed in the type).  A special type exists for
{\em colorings}, which are used to specify how a region should be partitioned into subregions.
Functions in Legion are named, accept one or more arguments and return a value of some type.
A function also declares what region access privileges and coherence it requires.  Function types
are universally quantified over all logical region bindings, with all argument and result types,
as well as the privileges and coherence requirements being expressed relative to the quantified
region names.
The final additional value type that Legion uses is a region relation.  Although logical regions
cannot be stored directly in variables, they can be captured as part of a region relation 
instance, which stores a value and one or more logical regions that satisfy a particular set of
constraints.  An instance of a region relation can be read out of the heap and unpacked, giving
new local names to the logical regions contained in the instance and tracking the constraints
between those new logical regions.

\subsection{Legion Core Type System}

The Legion Core language is explicitly typed, using judgments of the following form:

\begin{center}
$\typeenv{e}{T}$
\end{center}

where:
\begin{itemize}
\item $\Gamma$ is the type environment, mapping the names of local variables and global functions
to their types,
\item $\Phi$ is the region access privileges under which the expression will be evaluated, and
\item $\Omega$ is the set of constraints that must hold between regions
\end{itemize}

As regions are hierarchical, privileges and/or constraints on a region will often imply similar
privileges or constraints on subregions.  Figure~\ref{fig:closure} defines transitive closure
operations for $\Phi^*$ and $\Omega^*$ that will be used in some of the type checking rules.

The full set of type checking rules are in Figure~\ref{fig:types}.  Many of the rules are 
straightforward, but several deserve more explanation.

The Legion core language has no subtyping, even for pointers into regions that are part of a 
known region hierarchy.  The region ``scope'' of a pointer can only be changed via explicit
{\em upregion} and {\em downregion} operations, which check that the ``from'' and ``to'' regions
are in the right relationship.  It would have been possible to safely infer {\em upregion} calls,
but {\em downregion} calls must be accompanied by a run-time check that the pointer really does
point into the subregion(s), so {\em upregion} was made explicit as well for simplicity.

Accesses to heap memory are performed via the {\em read}, {\em write}, and {\em reduce}
operations, which are only legal if the region(s) in a pointers type are ones for which the
enclosing function has privileges to access.

Similarly, a call to another function is only permitted if the privileges required by the 
callee are a subset of those held by the caller.  There is no way to create privileges within
a Legion function - it is limited to those given to it by its caller.

The {\em partition} operation uses a {\em coloring} to split a region into one or more
disjoint subregions.  The subregions are given names within the body of the {\em partition},
as well as constraints that assert that each subregion is contained by the parent region and
the pairwise disjointness of the subregions.  These constraints can be used locally, or packed
into region relation instances that can be unpacked and used later.

The {\em pack} expression packs together a value and the corresponding set of logical regions,
as long as the constraints in the region relationship type can be shown to hold.  The
corresponding {\em unpack} expression gives (new) names to those regions.  Neither the 
{\em partition} nor the {\em unpack} expression allows aliasing of region names, simplifying the
handling of existing variables and region names.

\begin{figure*}
\centering{
\framebox{$\typeenv{bv}{bool}$}
\framebox{$\typeenv{iv}{int}$}
\finfrule
{\begin{array}{l}
\typeenvx e_1 : T_1 \\
\typeenvx e_2 : T_2
\end{array}}
{\typeenvx \langle e_1, e_2 \rangle : \langle T_1, T_2 \rangle}
\finfrule{\typeenvx e : \langle T_1,T_2 \rangle}{\typeenvx e\text{.1}\ : T_1}
\finfrule{\typeenvx e : \langle T_1,T_2 \rangle}{\typeenvx e\text{.2}\ : T_2}
\finfrule{\Gamma(id) = T}{\typeenvx id : T}
\framebox{$\typeenvx \text{null }T@r : T@r$}
\framebox{$\typeenvx \text{new }T@r : T@r$}
\finfrule{\typeenvx e : T@(\oton{r})}{\typeenvx \text{isnull}(e) : bool}
\finfrule
{\begin{array}{l}
\typeenvx e : T@(r'_1, \ldots r'_k) \\
\forall i. \exists j, r'_i \leq r_j \in \Omega^* \\
\end{array}}
{\typeenvx upregion(e,\oton{r}) : T@(\oton{r})}
\finfrule
{\begin{array}{l}
\typeenvx e : T@(r'_1, \ldots r'_k) \\
\forall j. \exists i, r_j \leq r'_i \in \Omega^* \\
\end{array}}
{\typeenvx downregion(e,\oton{r}) : T@(\oton{r})}
\finfrule
{\begin{array}{l}
\typeenvx e_1 : T@(\oton{r}) \\
\forall i, reads(r_i) \in \Phi^*\end{array}}
{\typeenvx \text{read}(e_1) : T}
\finfrule
{\begin{array}{l}
\typeenvx e_1 : T@(\oton{r}) \\
\typeenvx e_2 : T \\
\forall i, writes(r_i) \in \Phi^*
\end{array}}
{\typeenvx \text{write}(e_1, e_2) : T@(\oton{r})}
\finfrule
{\begin{array}{l}
\Gamma(id) = (T_1, T_2), \emptyset, \emptyset \rightarrow T_1 \\
\typeenvx e_1 : T_1@(\oton{r}) \\
\typeenvx e_2 : T_2 \\
\forall i, reduces_{id}(r_i) \in \Phi^*
\end{array}}
{\typeenvx \text{reduce}(id, e_1, e_2) : T_1@(\oton{r})}
\framebox{$\typeenvx \text{newcolor }r : \text{coloring}(r)$}
\finfrule{\begin{array}{l}
\typeenvx e_1 : \text{coloring}(r) \\
\typeenvx e_2 : T@r \\
\typeenvx e_3 : int
\end{array}}
{\typeenvx \text{color}(e_1, e_2, e_3) : \text{coloring}(r)}
\finfrule{\begin{array}{l}\typeenvx e_1 : int \\ \typeenvx e_2 : int\end{array}}{\typeenvx e_1 + e_2 : int}
\finfrule{\begin{array}{l}\typeenvx e_1 : int \\ \typeenvx e_2 : int\end{array}}{\typeenvx e_1 < e_2 : bool}
\finfrule{\begin{array}{l}
\typeenvx e_1 : T_1 \\
\typeenvx[G={\Gamma[id/T_1]}] e_2 : T_2
\end{array}}
{\typeenvx : \text{let}\ id : T_1 \text{in}\ e_2 : T_2}
\finfrule{\begin{array}{l}\typeenvx e_1 : bool \\ \typeenvx e_2 : T \\ \typeenvx e_3 : T\end{array}}{\typeenvx \text{if}\ e_1\ \text{then}\ e_2\ \text{else}\ e_3 : T}
\finfrule{
\begin{array}{l}
\Gamma(id) = \forall r'_1, \ldots r'_k.(\oton{T}),\Phi', Q' \rightarrow T_r \\
\typeenvx e_i : T_i[r_1/r'_1,\ldots,r_k/r'_k] \\
\Phi'[r_1/r'_1,\ldots,r_k/r'_k] \subseteq \Phi^*
\end{array}}
{\typeenvx id[\otok{k}{r}](\oton{e}) : T_r[r_1/r'_1,\ldots,r_k/r'_k]}
\finfrule{
\begin{array}{l}
\typeenvx e_1 : \text{coloring}(r_p) \\
\Omega' = \Omega \wedge \bigwedge_{i \in [1,k]} r_i \leq r_p \wedge \bigwedge_{1 \leq i < j \leq k} r_i * r_j \\
\typeenvx[O=\Omega'] e_2 : T \\
\{ \oton{r} \} \cap \textit{regions\_of}(\Gamma, T) = \emptyset
\end{array}}
{\typeenvx \text{partition}\ r_p\text{ using }e_1\text{ as }\otok{k}{r}\text{ in }e_2 : T}
\finfrule{
\begin{array}{l}
T_1 = \exists r'_1, \ldots r'_n.\ T_2\text{ where }\Omega_1 \\
\Omega_1[r_1/r'_1,\ldots,r_k/r'_k] \subseteq \Omega^* \\
\typeenvx e_1 : T_2[r_1/r'_1,\ldots,r_k/r'_k]
\end{array}}
{\typeenvx \text{pack}\ e_1\ \text{as}\ T_1[\otok{k}{r}] : T_1}
\finfrule{
\begin{array}{l}
T_1 = \exists r'_1, \ldots, r'_n.\ T_2\text{ where }\Omega_1 \\
\typeenvx e_1 : T_1 \\
\Gamma' = \Gamma[T_2[r_1/r'_1,\ldots,r_k/r'_k] / id] \\
\Omega' = \Omega \cup \Omega_1[r_1/r'_1,\ldots,r_k/r'_k] \\
\typeenvx[G=\Gamma',O=\Omega'] e_2 : T_3 \\
\{ \oton{r} \} \cap \textit{regions\_of}(\Gamma, T_1, T_3) = \emptyset
\end{array}}
{\typeenvx \text{unpack}\ e_1\ \text{as}\ id : T_1[\otok{k}{r}] \text{in}\ e_2 : T_3}
\finfrule{
\begin{array}{l}
\text{for }1 \leq i \leq p, \\
\Gamma(id_i) = \forall r_{i1}, \ldots r_{ik_i}. (T_{i1}, \ldots, T_{in_i}), \Phi_i, Q_i \rightarrow T_{ir} \\
\Gamma_i = \Gamma[a_{i1}/T_{i1}, \ldots, a_{in_i}/T_{in_i}] \\
\typeenv[G={\Gamma_i},P={\Phi_i},O=\emptyset]{e_i}{T_{ir}}
\end{array}}
{ 
\begin{array}{l@{ }l}
\vdash \{ & \text{task }id_1[r_{11}, \ldots, r_{1k_1}]( a_{11} : T_{11}, \ldots a_{1n_1} : T_{1n_1} ), \Phi_1, Q_1 : T_{1r} : e_1, \\
          & \ldots \\
          & \text{task }id_p[r_{p1}, \ldots, r_{pk_1}]( a_{p1} : T_{p1}, \ldots a_{pn_p} : T_{pn_p} ), \Phi_p, Q_p : T_{pr} : e_p \} : \bullet
\end{array} }
}
\caption{Legion Core Type System}
\label{fig:types}
\end{figure*}

\begin{figure}
\centering{
$\begin{array}{l}
\Omega \subseteq \Omega^* \\
r_i \leq r_j \in \Omega^*  \Rightarrow r_i \leq r_i \in \Omega^*\wedge r_j \leq r_j \in \Omega^* \\
r_i \leq r_j \in \Omega^* \wedge r_j \leq r_k \in \Omega^* \Rightarrow r_i \leq r_k \in \Omega^* \\
r_i \leq r_j \in \Omega^* \wedge r_j * r_k \in \Omega^* \Rightarrow r_i * r_k \in \Omega^* \\
r_i * r_j \in \Omega^* \Rightarrow r_j * r_i \in \Omega^* \\
\\
\Phi \subseteq \Phi^* \\
r_i \leq r_j \in \Omega^* \wedge reads(r_j) \in \Phi^* \Rightarrow reads(r_i) \in \Phi^* \\
r_i \leq r_j \in \Omega^* \wedge writes(r_j) \in \Phi^* \Rightarrow writes(r_i) \in \Phi^* \\
r_i \leq r_j \in \Omega^* \wedge reduces_{id}(r_j) \in \Phi^* \Rightarrow reduces_{id}(r_i) \in \Phi^* \\
reads(r) \in \Phi^* \wedge writes(r) \in \Phi^* \wedge \\
\hspace{1cm} \Gamma(id) = \forall \otok{k}{r}. (\oton{T}), \Phi', Q' \rightarrow T_r \Rightarrow reduces_{id}(r) \in \Phi^*
\end{array}$
}
\caption{Privilege and Constraint Closure}
\label{fig:closure}
\end{figure}

\subsection{Operational Semantics}

Operational semantics rules have the following form:

\begin{center}
$\opsenv{e}{v}{E}$
\end{center}

where: 
\begin{itemize}
\item $M$ is the mapping from logical regions $r_i$ in types to physical regions $\rho_i$, which are sets of memory locations.

It will be useful to apply this logical-to-physical mapping to other
things that defined in terms of logical regions to yield a corresponding definition in terms of
physical regions.  The notation $\hat x = M \llbracket x \rrbracket$ is used to describe the
result of replacing all free logical region names $r_i$ in $x$ with the corresponding physical
region $\rho_i$.  (Note that $M \llbracket x \rrbracket$ is not
well-formed if it contains a free logical region name $r_j \not\in dom(M)$.)
\item $L$ is the mapping of local variable names to their values on the stack.  These values are
immutable, and private to the function - it is not possible to get a pointer to a local value.
\item $H$ is the heap typing, mapping from memory locations to types.  The heap typing does not
change during the execution of a legion program.  The Legion type system is strong enough to
support the use of garbage collection
to allow the reuse of a memory location (potentially with a different type stored in that
location) once all existing references to it are dead, but we
do not consider that further in this paper.
\item $S$ is the store, mapping from memory locations $l_i$ to the current value stored.
\item $C$ is the ``clobber set'', a set of memory locations that may be accessed by concurrently executing operations (??? does this need to be split into read/write/reduce?)
\item $e$ is the expression being evaluated
\item $v$ is the result of the evaluation
\item $E$ is a memory trace (i.e. the effects) of the execution, a list of memory operations
in the order they were performed.  An operation $\epsilon$ is one of the following:
\begin{itemize}
\item $read(l, c, v)$, a read of location $l$ with coherence mode $c$, returning value $v$
\item $write(l, c, v)$, a write to location $l$ with coherence mode $c$, storing value $v$
\item $reduce_{id}(l, c, v)$, a reduction into location $l$ with coherence mode $c$ using a
commutative function $id$ with value $v$
\end{itemize}
where coherence modes are one of ({\em excl}, {\em atomic}, {\em simult}).

The following helper functions are used in some of the rules that deal with memory effects:
\begin{itemize}
\item $apply(S, E)$ is used to determine the effect on the store of a sequence of memory operations
\item $mark\_coherence(E, \hat Q)$ marks the memory operations in a subtask's trace to
constrain how the operations in that trace can be interleaved with other sibling tasks' operations
\item $valid\_interleave(S, C, E', \oton{E})$ is used to determine if $E'$ is a valid way to
interleave the memory traces of two or more subexpressions
\end{itemize}
Figure~\ref{fig:opsemfns} gives the definitions of {\em apply} and {\em mark\_coherence}.  For
the {\em valid\_interleave} predicate, we leave the precise definition to a later section.  For this
section, we need only one of the necessary conditions of a valid interleaving, that a valid
interleaving is at least an interleaving - it contains all the memory operations from each of the
constituent traces and no more, and that each trace's operations remain in order in the interleaved
trace.
\end{itemize}

There are a number of rules that appear to be nondeterministic, allowing multiple choices for
valid evaluation.  In reality, only the memory allocation case (i.e. new $T@r$) has a truly
nondeterministic choice (i.e. which currently-unused memory location of the right type to 
use).  A particular memory allocation algorithm is likely to be deterministic, but the
design of such algorithms is unrelated to the subject at hand, and by abstracting the location 
choice, we show that our results hold for any correct memory allocation algorithm.  (In fact,
our criteria are even weaker than that.  Our soundness result even holds if the location returned
by ``new $T@r$'' is one that is already in use, as long as the heap typing of that location is
correct.)

The remaining cases of apparent nondeterminism are the result of how we handle the semantics of
concurrent execution.  An operational semantics that explicitly tracks the state of all 
concurrently executing operations would allow precise specification of the result of each 
evaluation step, but would be extremely cumbersome.  Instead, we identify the cases in which
nonlocal effects (i.e. those that result from the concurrent evaluation of other expressions)
can impact the local evaluation, and make a ``guess'' of what value would result from an 
operation.  The check that the guess was consistent with the state of the system is deferred until
the previously nonlocal effects become local (i.e. contained within the evaluation of an enclosing
expression tree).  If the guess is not consistent, then the attempted proof of the subexpression's
behavior is flawed and must be reattempted.

In the case of ``read'' operations whose locations are in the clobber set $C$, we allow the local
evaluation to guess any value as long as it is of the right type.  The consistency of the value
is eventually checked by the $valid\_interleave$ predicate of some enclosing expression, but it
may not be the closest enclosing one.  The $valid\_interleave$ test itself allows some (apparent)
freedom of choice, deferring some of the consistency checks to the corresponding check further up
the expression tree.  The final case of apparent nondeterminism is in the choice of what initial
locations to include in the result of a ``newcolor $r$'' expression.  The inclusion of locations
beyond those which are explicitly requested by the application is necessary for the success of
subsequent memory allocation within a subregion created from a partitioning using the coloring, but
that allocation might not occur within the {\em partition} expression's
body.  Although the correctness of these partitioning guesses cannot be fully verified until the
entire execution is known, when an inconsistency is encountered (i.e. there isn't a location of
the right type in the right region for a ``new $T@r$'' expression) it is possible to ``patch'' the 
proof (by adding a previously unnamed location to the appropriate expanded colorings and giving
it the right type in $H$) rather than having to start the proof over from the beginning.

Most of the heavy lifting in the Legion core language occurs in the function call expression.
The expressions for all the function's arguments are evaluated in the caller's context, but a
new context is assembled for the evaluation of the function's body.  The region mapping used
in the callee only uses the caller's mapping indirectly - the only logical region names available
are those over which the called function is quantified.  Similarly, the set of local values is
replaced with a mapping of formal parameter names to the values of the arguments.  The store
is updated to account for side-effects of those argument evaluations.  Finally, if the function
being called operates with relaxed coherence (i.e. either {\em atomic} or {\em simult} instead of
{\em excl}), the locations with relaxed coherence are added to the clobber set, allowing the
impact of concurrent modifications of the store to be handled by the caller.  This is done by
annotating the called function's memory trace with the relaxed coherence on a per-location basis
and using the {\em valid\_interleave} predicate to control what parallel execution is allowed.

\begin{figure*}
\centering{
$
\begin{array}{lll}
apply(S, []) & = & S \\
apply(S, E \dplus [ read(l, c, v) ]) & = & apply(S, E) \\
apply(S, E \dplus [ write(l, c, v) ]) & = & apply(S, E)[v/l] \\
apply(S, E \dplus [ reduce_{id}(l, c, v) ]) & = & S'[id(S'(l), v)/l], \text{ where } S' = apply(S, E) \\
mark\_coherence([], \hat Q) & = & [] \\
mark\_coherence(E \dplus [ op(l, c, v) ], \hat Q) & = & mark\_coherence(E, \hat Q) \dplus \\
& & op(l, c', v), \text{ where } \\
& & c' =
\begin{cases}
simult, & \text{if }\exists \rho. l \in \rho \wedge simult(\rho) \in \hat Q \\
atomic, & \text{if }\exists \rho. l \in \rho \wedge atomic(\rho) \in \hat Q \\
excl, & \text{otherwise}
\end{cases} \\
any\_interleave([], [], \ldots, []) & = & true \\
any\_interleave([ \epsilon ] \dplus E', E_1, \ldots, [ \epsilon ] \dplus E_i, \ldots, E_n) & = & any\_interleave(E', E_1, \ldots, E_i, \ldots, E_n) \\
valid\_interleave(S, C, E', \oton{E}) & \Rightarrow & any\_interleave(E', \oton{E}) \\
\end{array}
$}
\caption{Operational Semantics Helper Functions}
\label{fig:opsemfns}
\end{figure*}

\begin{figure*}
\centering{\small
\framebox{$\opsenvx bv \mapsto bv, []$}
\framebox{$\opsenvx iv \mapsto iv, []$}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S' = apply(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \langle e_1, e_2 \rangle \mapsto \langle v_1, v_2 \rangle, E'}
\finfrule
{\opsenvx e \mapsto \langle v_1, v_2 \rangle, E}
{\opsenvx e\text{.1} \mapsto v_1, E} \hspace{1cm}
\finfrule
{\opsenvx e \mapsto \langle v_1, v_2 \rangle, E}
{\opsenvx e\text{.2} \mapsto v_2, E}
\finfrule
{L(id) = v}
{\opsenvx id \mapsto v, []}
\framebox{$\opsenvx \text{null }T@r \mapsto null, []$}
\finfrule
{\begin{array}{l}
l \in M(r) \\
H(l) = M \llbracket T \rrbracket
\end{array}}
{\opsenvx \text{new }T@r \mapsto l, []}
\finfrule
{\opsenvx e \mapsto l, E}
{\opsenvx \text{isnull}(e) \mapsto \textit{false}, E}
\finfrule
{\opsenvx e \mapsto null, E}
{\opsenvx \text{isnull}(e) \mapsto true, E}
\finfrule
{\opsenvx e \mapsto v, E}
{\opsenvx \text{upregion}(e, \oton{r}) \mapsto v, E}
\finfrule
{\begin{array}{l}
\opsenvx e \mapsto l, E \\
v = \begin{cases}
l, & \text{if $\exists i, l \in M(r_i)$}. \\
null, & \text{otherwise}.
\end{cases}
\end{array}}
{\opsenvx \text{downregion}(e, \oton{r}) \mapsto v, E}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto l, E \\
S' = \text{apply}(S, E) \\
v = \begin{cases}
S'(l), & \text{if } l \not\in C \\
v' : H(l), & \text{otherwise}
\end{cases}
\end{array}}
{\opsenvx \text{read}(e_1) \mapsto v, E \dplus [ read(l, excl, v) ]}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto l, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{write}(e_1, e_2) \mapsto l, E' \dplus [ write(l, excl, v) ]}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto l, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{reduce}(id, e_1, e_2) \mapsto l, E' \dplus [ reduce_{id}(l, excl, v) ]}
\finfrule{
\begin{array}{l@{}l}
K = \{ (l_1, iv_1), & \ldots, (l_p, v_p) \}, \text{ where } \\
& (\forall i \in [1,p]. l_i \in M(r)) \wedge \\
& (\forall i,j \in [1,p]. l_i \not= l_j)
\end{array}
}
{\opsenvx \text{newcolor }r \mapsto K, []}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto K, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto l, E_2 \\
S'' = \text{apply}(S', E_2) \\
\opsenvx[S=S''] e_3 \mapsto v, E_3 \\
K' = \{ (l,v) \} \cup \{ (l_i,v_i) : (l_i,v_i) \in K \wedge l \not= l_i \} \\
valid\_interleave(S, C, E', E_1, E_2, E_3)
\end{array}}
{\opsenvx \text{color}(e_1, e_2, e_3) \mapsto K', E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\
v' = v_1 + v_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx e_1 + e_2 \mapsto v', E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\
v' = \begin{cases}
true, & \text{if $v_1 < v_2$}. \\
\textit{false}, & \text{otherwise}.
\end{cases} \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx e_1 < e_2 \mapsto v', E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
L' = L[v_1/id] \\
S' = \text{apply}(S, E_1) \\
\opsenvx[L=L',S=S'] e_2 \mapsto v_2, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{let }id : T = e_1\text{ in }e_2 \mapsto v_2, E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto true, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2
\end{array}}
{\opsenvx \text{if }e_1\text{ then }e_2\text{ else }e_3 \mapsto v_2, E_1 \dplus E_2}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto \textit{false}, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_3 \mapsto v_3, E_3
\end{array}}
{\opsenvx \text{if }e_1\text{ then }e_2\text{ else }e_3 \mapsto v_3, E_1 \dplus E_3}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S_1 = \text{apply}(S, E_1) \\
\opsenvx e_2 \mapsto v_2, E_2 \\
\ldots \\
S_n = \text{apply}(S_{n-1}, E_n) \\
valid\_interleave(S, C, E', \oton{E})
\vspace{1.5mm} \\
\text{task }id[\otok{k}{r'}](a_1 : T_1, \ldots, a_n : T_n), \Phi', Q' : T_r = e_{n+1} \\
M' = \{ (r'_1, M(r_1)), \ldots (r'_k, M(r_k)) \} \\
L' = \{ (a_1, v_1), \ldots, (a_n, v_n) \} \\
S' = \text{apply}(S, E') \\
C' = C \cup \{ l : \exists \rho. atomic(\rho) \in M' \llbracket Q' \rrbracket \vee simult(\rho) \in M' \llbracket Q' \rrbracket \} \\
\opsenvx[M=M',L=L',S=S'] e_{n+1} \mapsto v_{n+1}, E_{n+1}
\vspace{1.5mm} \\
E'_{n+1} = mark\_coherence(E_{n+1}, M' \llbracket Q' \rrbracket) \\
valid\_interleave(S, C, E'', E', E_{n+1})
\end{array}}
{\opsenvx id[\otok{k}{r}](\oton{e}) \mapsto v_{n+1}, E''}
\finfrule{
\begin{array}{l}
\opsenv{e_1}{K}{E_1} \\
\rho_i = \{ l : (l, i) \in K \}, \text{ for } 1 \leq i \leq k \\
M' = M[\rho_1/r_1, \ldots, \rho_k/r_k] \\
S' = \text{apply}(S, E_1) \\
\opsenvx[M=M',S=S'] e_2 \mapsto v, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{partition}\ r_p\text{ using }e_1\text{ as }\otok{k}{r}\text{ in }e_2 \mapsto v, E'}
\finfrule{
\begin{array}{l}
\opsenvx e_1 \mapsto v, E \\
\rho_i = M[r_i], \text{ for } 1 \leq i \leq k \\
v' = \langle \langle \otok{k}{\rho}, v \rangle \rangle
\end{array}}
{\opsenvx \text{pack}\ e_1\ \text{as}\ T_1[\otok{k}{r}] \mapsto v', E}
\finfrule{
\begin{array}{l}
\opsenvx e_1 \mapsto \langle \langle \otok{k}{\rho} , v_1 \rangle \rangle, E_1 \\
M' = M[\rho_1/r_1, \ldots, \rho_k/r_k] \\
L' = L[v_1/id] \\
S' = \text{apply}(S, E_1) \\
\opsenvx[M=M',L=L',S=S'] e_2 \mapsto v_2, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{unpack}\ e_1\ \text{as}\ id : T_1[\otok{k}{r}] \text{in}\ e_2 \mapsto v_2, E' }
}
\caption{Legion Core Operational Semantics}
\label{fig:semantics}
\end{figure*}

\subsection{Soundness of Effects}

An important property of the legion type system is that any expression that is well-typed is
guaranteed to access the heap only in ways permitted by the privileges under which it was typed.
A judgement $M \vdash E : \Phi$ holds if all the memory operations in $E$ are of the types and
to locations covered by the privileges in $\Phi$:

\begin{center}
\begin{tabular}{l@{ }l@{ }l}
$M \vdash E : \Phi$ & $\Leftrightarrow$ & $\forall \epsilon\text { in } E.$ \\
& & $(\epsilon = read(l, c, v) \Rightarrow \exists r. l \in M(r) \wedge reads(r) \in \Phi)\ \wedge$ \\
& & $(\epsilon = write(l, c, v) \Rightarrow \exists r. l \in M(r) \wedge writes(r) \in \Phi)\ \wedge$ \\
& & $(\epsilon = reduce_{id}(l, c, v) \Rightarrow \exists r. l \in M(r) \wedge reduces_{id}(r) \in \Phi)$
\end{tabular}
\end{center}

The proof that $M \vdash E : \Phi$ holds for all well-typed Legion expressions is achieved by
induction over the structure of the expression.  Soundness is contingent on the following
consistent properties, which must be shown to hold for each subexpression:
\begin{itemize}
\item $M \sim \Omega$, a region mapping must satisfy the region constraints under which the expression was typed
\item $L \sim_H \Gamma$, the local values must have types consistent with the environment under which the expression was typed
\item $S \sim H$, the initial state of the store must contain values whose types are consisten with the heap typing
\end{itemize}

The proof requires two additional properties be proved for each subexpression:
\begin{itemize}
\item $v \sim_H M \llbracket T \rrbracket$, a subexpresion must evaluate to a value of the right type
\item $E \sim H$, the values written to the store must match the heap types of the location to which they're stored
\end{itemize}
Figure~\ref{fig:constprop} gives the precise definition of these properties.

\begin{figure*}
\centering{\footnotesize
$
\begin{array}{l}
\begin{array}{ll}
\begin{array}{lll}
M \sim \Omega & \Leftrightarrow & (\forall r_i, r_j. r_i \leq r_j \in \Omega \Rightarrow M(r_i) \subseteq M(r_j))\ \wedge \\
              &                 & (\forall r_i, r_j. r_i * r_j \in \Omega \Rightarrow M(r_i) \cap M(r_j) = \emptyset) \\
L \sim_H \Gamma & \Leftrightarrow & \forall (id,v) \in L. v \sim_H M \llbracket \Gamma \rrbracket (id) \\
S \sim H & \Leftrightarrow & \forall (l,v) \in S. v \sim_H H(l) \\
\end{array} & 
\begin{array}{lll}
E \sim H & \Leftrightarrow & (\forall l, c, v. write(l,c, v) \in E \Rightarrow v \sim_H H(l))\ \wedge \\
& & (\forall id, l, v. reduce_{id}(l, v) \in E \Rightarrow \\
& & (M \llbracket \Gamma \rrbracket (id) = (\hat T_1, \hat T_2), \emptyset, \emptyset \Rightarrow \hat T_1) \wedge H(l) = \hat T_1 \wedge v \sim_H \hat T_2) \\
\end{array}
\end{array} \vspace{3mm} \\
\begin{array}{l@{\hspace{1cm}}l}
\begin{array}{l}
bv \sim_H bool \\
iv \sim_H int \\
null \sim_H \hat T@\rho \\
\end{array} &
\begin{array}{lll}
l \sim_H \hat T@\rho & \Leftrightarrow & l \in \rho \wedge H(l) \sim_H \hat T \\
\langle v_1, v_2 \rangle \sim_H \langle \hat T_1, \hat T_2 \rangle & \Leftrightarrow & (v_1 \sim_H \hat T_1) \wedge (v_2 \sim_H \hat T_2) \\
\langle \langle \oton{\rho}, v \rangle \rangle \sim_H \text{rr}[\oton{r}] \hat T\text{ where }\Omega & \Leftrightarrow & (v \sim_H \hat T[\rho_1/r_1, \ldots \rho_n/r_n]) \wedge (\{ (r_i, \rho_i) \} \sim \Omega) \\
K \sim_H coloring(\rho) & \Leftrightarrow & \forall l_1, v_1. (l_1, v_1) \in K \Rightarrow (l_1 \in \rho\ \wedge \\
& & \forall l_2, v_2. (l_2, v_2) \in K \Rightarrow (l_1 \not= l_2) \vee (v_1 = v_2)) \\
\end{array}
\end{array}
\end{array}
$
}
\caption{Consistency Properties}
\label{fig:constprop}
\end{figure*}

\begin{thm}
Let $e$ be a well-typed Legion expression.  Let $M$ be a region mapping, $L$ be local value mapping,
$H$ be a heap typing, and $S$ be an initial state of the store satisfying the consistency properties:
$$
\begin{array}{l}
M \sim \Omega \\
L \sim_H \Gamma \\
S \sim H
\end{array}
$$
If $v$ and $E$ are the value and memory trace resulting from a permissable terminating evaluation of
$e$, then:
$$
\begin{array}{l}
v \sim_H M \llbracket T \rrbracket \\
E \sim H \\
M \vdash E : \Phi
\end{array}
$$
\end{thm}

Due to space constraints, we limit the discussion to the general strategy of the proof.  The full
proof can be found here\cite{LegionTypes12}.  If $v$ and $E$ are the result of a permissible evaluation of
$e$, then a proof exists of:
$$\opsenv{e}{v}{E}$$
The soundness of the result is shown by induction over the structure of this proof.  For each of 
the 23 different forms a Legion expression can have, we assume the soundness of the subexpressions'
evaluations (provided we can show the consistency of the mappings and store used by that
subexpression) and prove that the result of the expression's evaluation is sound.  Although there
are a multitude of cases to be proven, many of them are similar, and benefit from
the use of the following lemmas:

\begin{lem}
\label{lemma:heapconst:apply}
If $S \sim H$ and $E \sim H$, then $\text{apply}(S, E) \sim H$.
\end{lem}

\begin{lem}
\label{lemma:heapconst:effects1}
If $E_1 \sim H$ and $E_2 \sim H$, then $E_1 \dplus E_2 \sim H$.
\end{lem}

\begin{lem}
\label{lemma:heapconst:effects2}
If $E_1 \sim H$ and $E_2 \sim H$ and $valid\_interleave(S, C, E', E_1, E_2)$, then $E' \sim H$.
\end{lem}

\begin{lem}
\label{lemma:effsound:effects1}
If $M \vdash E_1 : \Phi$ and $M \vdash E_2 : \Phi$, then $M \vdash E_1 \dplus E_2 : \Phi$.
\end{lem}

\begin{lem}
\label{lemma:effsound:effects2}
If $M \vdash E_1 : \Phi$ and $M \vdash E_2 : \Phi$ and $valid\_interleave(S, C, E', E_1, E_2)$, then $M \vdash E' : \Phi$.
\end{lem}

\begin{lem}
\label{lemma:omegaclosure}
$M \sim \Omega^*$ if and only if $M \sim \Omega$.
\end{lem}

\begin{lem}
\label{lemma:phiclosure}
$M \vdash E : \Phi^*$ if and only if $M \vdash E : \Phi$.
\end{lem}

The proofs of these lemmas can also be found here\cite{LegionTypes12}.  The proof of the theorem is organized
into six pieces, one for each of the three consistency properties needed for subexpressions and one
for each of the three soundness properties we wish to show.

\begin{itemize}

\item Only three expressions have subexpressions that modify $M$ or $\Omega$ - those that don't
trivially satisfy the region mapping consistency requirement.  For the
{\em partition} expression, the assumed consistency of the coloring can be shown to preserve
the region mapping consistency with respect to the constraints.  Similarly, the consistency of 
a region relation instance guarantees the maintenance of consistency in an {\em unpack}
expression.  Finally, the body of a called function executes with a different region mapping,
but with an initially-empty set of constraints, so they are trivially satisfied.

\item Only three expression have subexpressions that modify $L$, $\Gamma$, $M$.  The
{\em partition} expression only modifies $M$, and the requirement that it not reuse existing
names ensures that $M \llbracket \Gamma \rrbracket$ does not change.  The value and type of the
binding created in a {\em let} expression is obviously consistent, while the binding created in
an {\em unpack} expression is less obviously so, requiring an induction over the type of the 
unpacked value to show equivalence under the new mapping.  The last case is again the body of a
called function, which requires the same style of proof as for the {\em unpack} expression to
be performed for each formal parameter.

\item The heap typing consistency of all stores used in subexpressions follows directly from
Lemma~\ref{lemma:heapconst:apply}.

\item With the necessary consistency conditions all satified, the inductive hypothesis asserts
the type consistency of all subexpression result values.  The consistency of the result of 
the {\em upregion} is guaranteed by the type checking requirement of appropriate subregion
constraints and the mapping's consistency with those constraints, whereas {\em downregion}
expression's result is consistent due to the run time check that is performed.  (The requirement
for appropriate constraints in the {\em downregion} typing rule is primarily for performance
(i.e. knowing which part of the region tree to examine) and to catch downcasts that will never
work at runtime.)

The consistency of a {\em read} expression's result is trivial when an address falls in the
clobber set, and counts on the consistency of the store otherwise.  The consistency of a 
{\em color} expression's result depends on the pointer subexpression's consistency and the 
removal of any previous coloring of that location from the coloring set.  The remaining
interesting cases arise from changes to the mapping $M$ rather than transformations on the
value $v$.  In the case of {\em partition} and {\em unpack} expressions, the type system's
requirement that the body subexpression's result not use the regions that were added to the
mapping allow the changes to the mapping to be ignored.  The last case is, yet again, the body
of a called function, and the same strategy that was used for the type consistency of the
formal parameters works in reverse for the function's result.

\item The type consistency of the value in an expression's effect follows from
Lemmas~\ref{lemma:heapconst:effects1} and~\ref{lemma:heapconst:effects2}.  New effects are
added by the {\em write} and {\em reduce} expressions, but their values' consistency follows
directly from the inductive hypothesis on their subexpressions.  Finally, the consistency of the
values in a called function's memory trace is addressed in the same way as the return value.

\item The proof of the crucial property of containment of effects within the available privileges
is very similar to the previous step, with Lemmas~\ref{lemma:effsound:effects1}
and~\ref{lemma:effsound:effects2} covering most cases, straightforward proofs for the {\em read},
{\em write}, and {\em reduce} expressions, and one final special case for function calls.  The 
inductive hypothesis asserts that the function body's effects are contained within its own
privileges.  Those are a subset of the caller's $\Phi^*$, and then Lemma~\ref{lemma:phiclosure}
is used to complete the proof.
\end{itemize}

%% \begin{table*}
%% \centering
%% {\small
%% \begin{tabular}{l|p{5cm}|p{5cm}|p{5cm}}
%% {\bf Rule} & 
%% \multicolumn{1}{|c|}{$\mathbf{v \sim_H M \llbracket T \rrbracket}$} &
%% \multicolumn{1}{|c|}{$\mathbf{E \sim H}$} &
%% \multicolumn{1}{|c|}{$\mathbf{E : \Phi}$} \\
%% \hline
%% BoolConst & & & \\
%% IntConst & & & \\
%% TupleBuild & & & \\
%% TupleField & & & \\
%% LocalVar & & & \\
%% NullPtr & & & \\
%% NewPtr & & & \\
%% IsNull & & & \\
%% UpRegion & & & \\
%% DownRegion & & & \\
%% Read & & & \\
%% Write & & & \\
%% Reduce & & & \\
%% Newcolor & & & \\
%% Color & & & \\
%% IntMath & & & \\
%% IntCmp & & & \\
%% Let & & & \\
%% IfElse & & & \\
%% TaskCall & & & \\
%% Partition & & & \\
%% Pack & & & \\
%% Unpack & & &
%% \end{tabular}}
%% \caption{Proof pieces}
%% \end{table*}


\subsection{Coherence}

The soundness proof above guarantees that the evaluation of an expression produces a value of the
right type, and do so within the regions of memory for which privileges are held, but for the
Legion programming model to be useful, we need to also guarantee that the evaluation of an expression
produces the (or at least, a) correct value.  The key to doing this is to place additional 
constraints on what it means to be a valid interleaving of two or more memory traces.  In
addition to a valid interleaving being an interleaving of the individual traces, we will 
require that it be:
\begin{itemize}
\item {\em coherent} - each memory read operation should see the effect of all writes and reductions 
that occur earlier in the interleaved trace to the same location, and
\item {\em sequentially equivalent} - the value read by each memory read operation and the result of applying the interleaved trace to the original store should be the same as if each constituent trace
was applied to the store in a valid {\em program order}.
\end{itemize}
These requirements are relaxed in some cases due to either a non-empty clobber set (representing
operations that may occur concurrently as part of evaluating other functions) or due to coherence
modes other than {\em excl} on operations with the traces (representing operations that may 
occur concurrently as part of evaluating other parts of the same function).

\begin{figure*}
$$
\begin{array}{lll}
valid\_interleave(S, C, E', \oton{E}) & = & any\_interleave(E', \oton{E}) \wedge \\
& & coherent(S, L_{excl}(E', C), L_{excl}(E', C), E')\ \wedge \\
& & seq\_equiv(S, L_{excl}(E', C), L_{excl}(E', C), E', \oton{E})\ \wedge \\
& & coherent(S, L_{atomic}(E', C), \emptyset, E')\ \wedge \\
& & \exists \oton{\pi}, (\oton{\pi}) \text{ is a permutation of } (1,\ldots,n)\ \wedge \\
& & \ \ \ seq\_equiv(S, L_{atomic}(E', C), \emptyset, E', E_{\pi_1}, \ldots, E_{\pi_n}) \\
coherent(S, L_1, L_2, []) & = & \text{true} \\
coherent(S, L_1, L_2, \epsilon \dplus E) & = &\
\begin{cases}
(l \in L_2 \Rightarrow S(l) = v)\ \wedge \\
\ \ \ coherent(S, L_1, L_2, E), & \text{if $\epsilon = read(l, c, v)$} \\
coherent(apply(S, \epsilon), L_1, L_2 \cup \{ l \}, E), & \text{if $\epsilon = write(l, c, v)$ and $l \in L_1$} \\
coherent(apply(S, \epsilon), L_1, L_2, E), & \text{otherwise}
\end{cases} \\
seq\_equiv(S, L_1, L_2, E', \oton{E}) & = & coherent(S, L_1, L_2, E_1 \dplus \ldots \dplus E_2)\ \wedge \\
& & \forall l \in L_1. apply(S, E')(l) = apply(S, E_1 \dplus \ldots \dplus E_n)(l) \\
L_{excl}(E, C) & = & \{ l : op(l, excl, v) \text{ in } E  \} \setminus C \\
L_{atomic}(E, C) & = & \{ l : op(l, atomic, v) \text{ in } E \} \setminus (C \cup L_{excl}(E, C)) \\
\end{array}
$$
\caption{Valid Interleaving Test}
\label{fig:validinterleave}
\end{figure*}

Figure~\ref{fig:validinterleave} gives the precise definition of the {\em valid\_interleave}
predicate, but there are a lot of moving parts, so description in ``plain'' English may help.
Consider a set of constituent traces $\oton{E}$.  Let the {\em exclusive location set} $L_{excl}$ be
the set of all locations that appear in at least one operation with coherence mode $excl$ in at least
one constituent trace, excepting any locations in the clobber set $C$.  Let the {\em atomic location
set} $L_{atomic}$ similarly be the set of locations that appear in at least one operation with 
coherence mode $atomic$, but no operations with coherence mode $excl$, again excepting any location
in the clobber set.  The $coherent(S,L_1,L_2,E)$ test checks that all reads of locations in $L_2$ and any read of a location in $L_1$ that comes after a write to the same location return values
that match what was most recently written into the store.  (The difference betwen $L_1$ and $L_2$
defers the checking of atomic reads that don't have a preceeding write until any other traces that
may be ordered before $E$ are included.)  The $seq\_equiv$ test verifies that every read in $E'$ with a location in $L_1$ would also have be coherent if the operations were performed in the original program order and that the store that results from applying $E'$ matches the store that would
have resulted from applying the constituent traces in program order for all locations in $L_1$.
For the atomic location set, we allow the constituent traces to be permuted, but all locations
must be checked with the same permutation.

Flexibility in interleaving operations is the key to achieving parallel execution, but
hopefully the reader will agree that the exact criteria for creating a valid interleaving is
much too expensive to implement at runtime, so we now consider whether there are simpler ways to
generate valid interleavings, and under what conditions those approaches may be used.

The first option available to us is to serialize the constituent traces into the original
program order.  Although each constituent trace can be assumed to be coherent, that coherence is
in the context of a clobber set that may differ from the one in which the interleaving must occur.
As discussed earlier, this difference can result in cases where no valid interleaving exists.
However, we can show that as long as any valid interleavings exist, the serialization of the
constituent traces will be one of them.

To prove this result, we will use the following lemma:

\begin{lem}
\label{lemma:applychain}
For any initial store $S$ and memory traces $E_1$ and $E_2$,
$$apply(S, E_1 \dplus E_2) = apply(apply(S, E_1), E_2).$$
\end{lem}

The proof of this follows directly from the definition of $apply$.

\begin{thm}
\label{thm:sequential}
Let $S_0$ be an initial store, $C$ be a clobber set and $\oton{E}$ be memory traces to be
interleaved.  Let $E' = E_1 \dplus \ldots \dplus E_n$.  If there exists any $E''$ that is a
valid interleaving of $\oton{E}$, then $E'$ is also valid interleaving of $\oton{E}$.
\end{thm}

\begin{proof}
To prove $valid\_interleave(S_0, C, E', \oton{E})$, we need to show the three conditions hold:
\begin{enumerate}
\item $any\_interleave(E', \oton{E})$ is intuitively obvious, and can be proven by induction over 
the length of $E_1$, followed by $E_2$, and so on.
\item $coherent(S_0, C, E')$ is shown by considering each constituent trace's subsequence in $E'$
in order, using Lemma~\ref{lemma:applychain} along with the coherence of each $E_i$.
\item $seq\_equiv(S_0, C, E', \oton{E})$ is trivial, as each leading subsequence of $E'$ corresponds
to the appropriate pieces of $\otok{i}{E}$.
\item $coherent(S_0, C, E')$ can be shown from the sequential equivalence of $E''$.  The value 
returned by each read in $E''$ has been shown to be equal to the value in the store that results
from the application of all previous constituent traces and the operations before the read in its
own trace.  This is exactly the sequence of preceding operations of the corresponding read in $E'$,
and Lemma~\ref{lemma:applychain} allows us to trainsform the chain of $apply$ operations into a 
single $apply$ operation on the whole sequence, satisfying the coherence condition for the read
in $E'$.  This property applies for all reads in $E''$, and since both $E'$ and $E''$ are
interleavings of the same traces, they have exactly the same reads, so we have shown all the reads
in $E'$ to be coherent.
\end{enumerate}
\end{proof}

Now that we have a way to construct a valid interleaving, we can look at how to modify that
interleaving to get interleavings that are still valid, but allow parallel execution.  To do this,
we consider the criteria under which we may swap the order of two adjacent memory operations in an
existing valid interleaving.
\begin{itemize}
\item First, the two operations must have come from different constituent
traces, or the swap would violate the $any\_interleave$ criterion.
\item Second, if one is a read of
a location (that is not in the clobber set), the other may not be a write or reduce to the same
location, as changing the order would almost certainly change the value that is read.
\item Third, if one is a write of a location, the other may not be a write or reduce to the same
location, as the store that would result from applying those operations in the opposite order would
show a difference in that location.
\item Finally, if both operations are reductions to the same location, they may be swapped if they
use the same reduction function, as reduction functions are assumed to be commutative.  (We 
follow the example of other work (i.e. DPJ) and leave proofs of commutativity to the programmer,
possibly with the aid of other tools.)  However, if they use different reduction functions (by
name - we make no attempt to compare the operation of functions), commutative cannot be 
guaranteed and swapping the two operations might result in a different resulting store.
\end{itemize}

To summarize this, we define a {\em noninterference} operator on two effects that have been
annotated with which constituent trace they came from as follows:
$$
\begin{array}{l@{ }l}
op_1^{E_1}(l_1, c_1,& v_1)\ \nonint\ op_2^{E_2}(l_2, c_2, v_2) \Leftrightarrow E_1 \not= E_2\ \wedge \\
& \big( l_1 \not= l_2 \vee (op_1 = read \wedge op_2 = read)\ \vee \\
& (op_1 = reduce_{id_1} \wedge op_2 = reduce_{id_2} \wedge id_1 = id_2) \big)
\end{array}
$$

\begin{lem}
\label{lem:nonintswap}
Let $S$ be an initial store, $C$ be a clobber set, $\oton{E}, E'_a, E'_b$ be memory traces, and
$\epsilon_1, \epsilon_2$ be two annotated memory operations such that $\epsilon_1 \nonint \epsilon_2$.
Then,
$$valid\_interleave(S, C, E'_a \dplus \epsilon_1 \dplus \epsilon_2 \dplus E'_b, \oton{E})$$
if and only if
$$valid\_interleave(S, C, E'_a \dplus \epsilon_2 \dplus \epsilon_1 \dplus E'_b, \oton{E}).$$
\end{lem}

\begin{proof}
As before, we consider the three conditions needed to be a valid interleaving.  We describe the
implication in the ``forward'' direction, but the arguments are all symmetric.
\begin{enumerate}
\item If $E'_a \dplus \epsilon_1 \dplus \epsilon_2 \dplus E'_b$ is an interleaving of $\oton{E}$,
the proof must first ``pop off'' all of $E'_a$, leaving $\epsilon_1 \dplus \epsilon_2 \dplus E'_b$ for
the interleaved subtrace.  The next two steps must pop $\epsilon_1$ and $\epsilon_2$, leaving $E'_b$.
They cannot be in the same subtrace because $\epsilon_1 \nonint \epsilon_2$, so we could also pop
$\epsilon_2$ and then $\epsilon_1$, resulting in a proof that $E'_a \dplus \epsilon_2 \dplus \epsilon_1 \dplus E'_b$ is also an interleaving of the constituent traces.
\item For coherence, we must show the value read (if any) by $\epsilon_1$ does not change, the value
read (if any) by $\epsilon_2$ does not change, and that any read in $E'_b$ sees no change.  With the
help of Lemma~\ref{lemma:applychain}, we can eliminate the common $E'_a$ from all sequences by
using $S' = apply(S, E'_a)$.  Similarly to show that $apply(S', \epsilon_1 \dplus \epsilon_2 \dplus E) = apply(S', \epsilon_2 \dplus \epsilon_1 \dplus E)$ for any $E$, we need only to show that it holds
for $E = []$.  The proof is now reduced to showing the following:
\begin{enumerate}
\item $\epsilon_1 = read(l, c, v) \Rightarrow S'(l) = apply(S',\epsilon_2)(l)$ - since $\epsilon_1$
is a read, either $\epsilon_2$ must be a read (in which case $apply(S, \epsilon_2) = S'$) or must be
to a different location, so the result of applying just it to $S'$ cannot change the value in 
location $l$.
\item $\epsilon_2 = read(l, c, v) \Rightarrow apply(S', \epsilon_1)(l) = S'(l)$ - this is the same
as above, with $\epsilon_1$ and $\epsilon_2$ switched.
\item $apply(S', \epsilon_1 \dplus \epsilon_2) = apply(S', \epsilon_2 \dplus \epsilon_1)$ - we must
show that the two store operations $apply(\bullet, \epsilon_1)$ and $apply(\bullet, \epsilon_2)$
commute.  Modifications to two different locations commute, as do two reads (which make no change
to the store).  Finally, two reductions using the same function to the same location also commute.
\end{enumerate}
\item The proof that sequential equivalence is maintained comes down to showing the final store
is identical after the swap of the two operations, and this is merely a special case of the third
piece of the coherence proof.
\end{enumerate}
\end{proof}

We now extend the noninterference operator to entire memory traces, providing a way to say that
no operation in a trace interferes with any operation in other:
$$E_1 \nonint E_2 \Leftrightarrow \displaystyle\bigwedge_{\epsilon_1 \text{ in } E_1, \epsilon_2 \text{ in } E_2} \epsilon_1 \nonint \epsilon_2$$
and observe that this property permits arbitrary ordering (i.e. parallel execution) of the 
corresponding subexpressions.

\begin{lem}
\label{lem:noninteffects}
Let $S$ be an initial store, $C$ be a clobber set, $\oton{E}$ be memory traces such that $E_i \nonint E_j$
for every $1 \leq i < j \leq n$.  Then any trace $E'$ satisfying:
$$any\_interleave(E', \oton{E})$$
is a valid interleaving.
\end{lem}

\begin{proof}
We will use Theorem~\ref{thm:sequential} and Lemma~\ref{lem:nonintswap} to make repeated swaps
of adjacent operations to transform $E'$ into $E_1 \dplus \ldots \dplus E_n$.  The symmetry of
Lemma~\ref{lem:nonintswap} is then used to show that the validity of $E_1 \dplus \ldots \dplus E_n$
under Theorem~\ref{thm:sequential} implies the validity of $E'$.

The swapping algorithm as follows: Associate with each operation in $E'$ the index of that operation
in $E_1 \dplus \ldots \dplus E_n$.  Any consectutive pair of operations $\epsilon_1$ and $\epsilon_2$
for which $index(\epsilon_1) > index(\epsilon_2)$ is a {\em misordered pair}.  For any such pair,
$\epsilon_1$ and $\epsilon_2$ will be from different constituent traces (if they were from the same
trace, their misordering would mean that $E'$ was not an interleaving of $\oton{E}$).  Every pair of
traces is noninterfering, so $\epsilon_1 \nonint \epsilon_2$ and they can be swapped while preserving
validity of the trace.  At most $n^2/2$ swaps are needed to eliminate all misordered pairs.
\end{proof}

Our next step is to extend noninterference to the privileges used in the type system.  We will make
use of the region mapping $M$ to translate the logical regions named in privileges into sets of
locations (i.e. physical regions), and define noninterference between individual privileges as
follows:
$$
\begin{array}{l@{ }l}
priv_1(r_1) \nonint[M] & priv_2(r_2) \Leftrightarrow (M(r_1) \cap M(r_2) = \emptyset)\ \vee \\
& (priv_1 = reads \wedge priv_2 = reads)\ \vee \\
& (priv_1 = reduces_{id_1} \wedge priv_2 = reduces_{id_2} \wedge id_1 = id_2)
\end{array}
$$
%% \begin{center}
%% \begin{tabular}{llc}
%% \multicolumn{1}{c}{$\phi_1$} & \multicolumn{1}{c}{$\phi_2$} & $\phi_1 \nonint[M] \phi_2$? \\
%% \multirow{3}{*}{$reads(r_1)$} & $reads(r_2)$ & true \\
%% & $writes(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $reduces_{id_2}(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% \cline{1-1}
%% \multirow{3}{*}{$writes(r_1)$} & $reads(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $writes(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $reduces_{id_2}(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% \cline{1-1}
%% \multirow{3}{*}{$reduces_{id_1}(r_1)$} & $reads(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $writes(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $reduces_{id_2}(r_2)$ & $\begin{array}{c}id_1 = id_2 \vee \\ M(r_1) \cap M(r_2) = \emptyset\end{array}$ \\
%% \end{tabular}
%% \end{center}
and noninterference between sets of privileges in the same way as memory traces:
$$\Phi_1 \nonint[M] \Phi_2 \Leftrightarrow \displaystyle\bigwedge_{\phi_1 \in \Phi_1, \phi_2 \in \Phi_2} \phi_1 \nonint[M] \phi_2$$

\begin{lem}
\label{lem:nonintpriv}
Let $M$ be a region mapping and $E_1$ and $E_2$ two memory traces such that $M \vdash E_1 : \Phi_1$ and $M \vdash E_2 : \Phi_2$.  If $\Phi_1$ and $\Phi_2$ are noninterfering under $M$, then $E_1$ and $E_2$ must be noninterfering.
\end{lem}

\begin{proof}
The proof is by contradiction.  Assume $E_1 \cancel\nonint E_2$.  Then there must be some $\epsilon_1$ in $E_1$ and some $\epsilon_2$ in $E_2$ such that $\epsilon_1 \cancel\nonint \epsilon_2$.  This requires that
$\epsilon_1$ and $\epsilon_2$ be operations to the same location $l$ and not both be reads or both
reductions using the same function name.  Assume $\epsilon_1 = read(l, c_1, v_1)$ and $\epsilon_2 = write(l, c_2, v_2)$.  The definition of $M \vdash E_1 : \Phi_1$ tells us that there must be some $r_1$ satisfying $l \in M(r_1) \wedge reads(r_1) \in \Phi_1$.  Similarly, there must be some $r_2$ satisfying $l \in M(r_2) \wedge writes(r_2) \in \Phi_2$.  Letting $\phi_1 = reads(r_1)$ and $\phi_2 = writes(r_2)$, we have $M(r_1) \cap M(r_2) \not= \emptyset$ (it contains at least $l$), so $\phi_1 \cancel{\nonint[M]} \phi_2$ and $\Phi_1 \cancel{\nonint[M]} \Phi_2$.  There are seven other cases to consider (using $id_1 \not= id_2$ for the reduce-reduce case), but all yield the same result.
\end{proof}

We are now able to connect the dots and get to the key result that allows the Legion runtime to 
safely run subtasks in parallel.

\begin{thm}
\label{thm:parallelexec}
Let $\oton{e}$ be well-typed Legion expressions, each with its own privileges $\Phi_i$.
Let $M$ be a region mapping, $L$ be local value mapping,
$H$ be a heap typing, and $S$ be an initial state of the store satisfying the consistency properties:
$$
\begin{array}{l}
M \sim \Omega \\
L \sim_H \Gamma \\
S \sim H
\end{array}
$$
If $\Phi_i \nonint[M] \Phi_j$ for $1 \leq i < j \leq n$, then any parallel execution of expressions
$\oton{e}$ will result in a valid interleaving of memory operations.
\end{thm}

The proof follows directly from Lemma~\ref{lem:nonintpriv} and Lemma~\ref{lem:noninteffects}. \\

Noninterference of effects is something that can only be determined after
evaluation of an expression is completed, and only at great expense (see STM).
In contrast, the noninterference of privileges can be efficiently determined at
runtime.  Even though the privileges themselves are static, the
mapping $M$ can be dynamically determined, allowing noninterference to be 
judged in many more cases than a purely static analysis can achieve.

Note that this result holds even if the clobber set $C$ is non-empty.  This allows 
two ``locally independent'' subtasks to run in parallel even if one or both
of them is interacting (in a programmer-permitted way) with a third subtask.

\subsection{Relaxed Coherence}

The analysis above did not consider the coherence modes on each operation in the memory traces,
making the worst-case assumption that all were using the $excl$ mode.  However, if two or more
subexpressions contain calls to functions that use $atomic$ and/or $simult$ coherence modes
on some of their regions, options other than serial execution may be guaranteed to 
result in valid interleavings even if constituent traces have some locations in common.  There
are two cases of particular interest that we will cover.  In each case, the entirety of the 
reasoning from the previous section is repeated with minor modifications, so we will limit our
discussion to a general description of the differences rather than the complete proofs.

The first important case occurs when all apparently-interfering operations have coherence modes
of either $atomic$ or $simult$.  In this case, we can see that the conditions required for
coherence and sequential equivalence are satisfied for all locations in $L_{excl}$.  The
requirements for locations in $L_{atomic}$ allow for any permutation of the constituent traces,
so the runtime is free to serialize the execution of the subexpressions in any order, not just
the original program order.

In order to convert the required analysis to one that can be performed on regions, we modify
the noninterference operator for effects to consider only locations in $L_{excl}$ and show that
traces that a noninterfering under this modified check satisfy the requirement for atomic
execution.  We then modify the noninterference operator on privileges to allow 
$M(r_1) \cap M(r_2) \not= \emptyset$ if either $atomic(r_1)$ or $simult(r_1)$ is in $Q_1$ and
either $atomic(r_2)$ or $simult(r_2)$ is in $Q_2$, and can show that subexpressions with 
privileges that can be shown to be ``atomically noninterfering'' (under a dynamic region mapping
$M$) will always have effects that are compatible with atomically-reordered execution.  Finally,
in the special case where each subexpression has $atomic(r)$ or $simult(r)$ in $Q_i$ for every $r$
in $\Phi_i$, we can eliminate the dynamic check entirely.

The second case is a subset of the first, in which all apparently-interfering operations have
the $simult$ coherence mode.  In this case, all the coherence and sequential equivalence 
checks are trivially satisfied, and any interleaving of the constituent traces will be valid.
We again modify the noninterference criteria for effects, traces, and privileges, this time
only allowing $simult$ coherence annotations, and can show that subexpression with privileges
that can be shown to be ``simulataneously noninterfering'' (under mapping $M$) can be executed
in parallel.  This will include all the cases covered by Theorem~\ref{thm:parallelexec} as well
as those where the programmer has used the $simult$ coherence mode to explicitly allow parallel
execution.  Again, a special (but important) case exists where all privileges for each
subexpression are paired with $simult$ coherence mode declarations, allowing the safety of
parallel execution to be determined at compile time.

\subsection{Hierarchical Scheduling}

The enforcement of a (locally) valid interleaving at every step in the operational semantics
captures the hierarchical nature of the scheduler used by the Legion runtime.  As the cost of
a scheduling decision is quadratic in the number of tasks (more precisely, the number of 
privileges for those tasks), it should be clear that a hierarchical scheduling algorithm will
be vastly more efficient than a global algorithm that must consider the privileges of every
concurrently executing expression.
However, a scheduling algorithm that makes decisions hierarchically must do so with limited
information, and must respect all required scheduling dependencies while ideally imposing as
few extra dependencies as possible.

Let $e_1$ and $e_2$ be well-typed Legion expressions that using privileges $\Phi_1$ and
$\Phi_2$.  Now let $e_3$ be some subexpression of $e_1$ and $e_4$ be some 
subexpression of $e_2$, with corresponding privileges $\Phi_3$ and $\Phi_4$.

By Theorem~\ref{thm:parallelexec}, if the runtime can verify $\Phi_1 \nonint[M] \Phi_2$, then 
expressions $e_1$ and $e_2$ may be evaluated in parallel.  The evaluation of the subexpressions
$e_3$ and $e_4$ will therefore be allowed to run in parallel, and we must show that this is
permissible.  We do so by proving that any memory traces that can result from the evaluation
of the subexpression must be noninterfering (allowing parallel execution by
Lemma~\ref{lem:noninteffects}).

\begin{thm}
\label{thm:hiersched}
Let $e_1$ and $e_2$ be well-typed Legion expressions that using privileges $\Phi_1$ and
$\Phi_2$.  Now let $e_3$ be some subexpression of $e_1$ and $e_4$ be some 
subexpression of $e_2$.  For any memory traces $E_3$ and $E_4$ that result from evaluation of
$e_1$ and $e_2$ (with the usual consistent $M$, $L$, $H$, and $S$), $E_3$ and $E_4$ must be
noninterfering.
\end{thm}

\begin{proof}
Let $E_1$ be the result of an evaluation of $e_1$, with $E_3$ being the memory trace from the
evaluation of $e_3$ within the expression tree.  $E_1$ will be formed from a tree of valid
interleavings, each of which must include all the memory operations of each consitituent trace.
By induction over the number of intermediate subexpressions between $e_1$ and $e_3$, we
can show that any memory operation $\epsilon_3$ that is in $E_3$ must also be in $E_1$.
Similarly, any memory operation $\epsilon_4$ that is in $E_4$ must also be in $E_2$.  We have
$E_1 \nonint E_2$ from Lemma~\ref{lem:nonintpriv}, so and therefore $\epsilon_3 \nonint \epsilon_4$.  Since
this holds for all $\epsilon_3$ in $E_3$ and all $\epsilon_4$ in $E_4$, we have $E_3 \nonint E_4$.
\end{proof}

Although a decision that $e_1$ and $e_2$ are noninterfering guarantees that $e_3$ and $e_4$ are
noninterfering, the converse is not true.  It is possible for $e_1$ and $e_2$ to be judged to be
potentially interfering and be serialized in their entirety even when the subexpressions could
have been proven to be noninterfering.  This loss of precision can impact performance, and did
for a few times during the implementation of our experiments.  When the performance impact is
significant, two options exist to improve the precision.  In cases where the $e_1$ and $e_2$ are
in fact noninterfering, the partitioning of regions can be further refined to make the
disjointness visible in the privileges.  Alternately, and this is the only option when the 
interference is dynamically determined, the code can be refactored to life the subexpressions
(or some expression containing them) up to the same level, allowing the dynamic test based on
the region mapping to infer noninterference in more cases.  Although this can increase the
overhead of scheduling decisions, judicious use of this technique in practice has not shown
any measurable performance degradation.

