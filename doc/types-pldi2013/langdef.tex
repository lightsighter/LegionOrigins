\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}

\newcommand{\oton}[1]{{#1}_1,\ldots,{#1}_n}
\newcommand{\otok}[2]{{#2}_1,\ldots,{#2}_{#1}}
\newcommand{\dplus}{\text{+\!+}}
\newcommand{\llbracket}{[\![}
\newcommand{\rrbracket}{]\!]}
\newcommand{\tuple}[2]{\langle #1, #2 \rangle}
\makeatletter
% macros for consistency flavors
\newcommand{\simH}{\sim_{\!H}}
% usually: \mapconsist{\Omega}
\newcommand{\mapconsist}[2][M]{#1 \sim #2}
% usually: \localconsist{L}{\Gamma}
\newcommand{\localconsist}[3][M]{#2 \simH \@ifmtarg{#1}{#3}{#1 \llbracket #3 \rrbracket}}
% usually: \storeconsist{S}{H}
\newcommand{\storeconsist}[2]{#1 \sim #2}
% usually: \valueconsist{v}{T}
\newcommand{\valueconsist}[3][M]{#2 \simH \@ifmtarg{#1}{#3}{#1 \llbracket #3 \rrbracket}}
% usually: \traceconsist{E}
\newcommand{\traceconsist}[2][H]{#2 \sim #1}
% usually: \privconsist{E}{\Phi}
\newcommand{\privconsist}[3][M]{#2 \@ifmtarg{#1}{:}{:_{\!#1}} #3}

\newcommand{\nonint}[1][]{\#\@ifmtarg{#1}{}{_{\!\!#1}}}
\makeatother

% override BCP's typesetrule function to left-justify multiple lines of hypotheses
\renewcommand{\typesetrule}[2]{%
   \setrulebody{%
      \frac{\begin{array}{@{}l@{}}#1\end{array}}%
           {\begin{array}{@{}l@{}}#2\end{array}}}}

% fun latex tricks to make typeenv and opsenv more friendly
\makeatletter
\define@key{typeenv}{G}{\def\typeenv@G{#1}}
\define@key{typeenv}{P}{\def\typeenv@P{#1}}
\define@key{typeenv}{O}{\def\typeenv@O{#1}}
\newcommand{\typeenvx}[1][]{
{
% default values
\def\typeenv@G{\Gamma}
\def\typeenv@P{\Phi}
\def\typeenv@O{\Omega}
\setkeys{typeenv}{#1}
\typeenv@G, \typeenv@P, \typeenv@O \vdash \,
}}
\newcommand{\typeenv}[3][]{\typeenvx[#1] {#2} : {#3}}
\define@key{opsenv}{M}{\def\opsenv@M{#1}}
\define@key{opsenv}{L}{\def\opsenv@L{#1}}
\define@key{opsenv}{H}{\def\opsenv@H{#1}}
\define@key{opsenv}{S}{\def\opsenv@S{#1}}
\define@key{opsenv}{C}{\def\opsenv@C{#1}}
\newcommand{\opsenvx}[1][]{
{
% default values
\def\opsenv@M{M}
\def\opsenv@L{L}
\def\opsenv@H{H}
\def\opsenv@S{S}
\def\opsenv@C{C}
\setkeys{opsenv}{#1}
\opsenv@M, \opsenv@L, \opsenv@H, \opsenv@S, \opsenv@C \vdash \,
}}
\newcommand{\opsenv}[4][]{\opsenvx[#1] {#2} \mapsto {#3}, {#4}}
\makeatother

\begin{figure*}
\centering
{\small
\begin{tabular}{cclr|cclr}

$T$ & ::= &  & types & $bv$ & ::= & false $\;\;\;\mid\;\;\;$ true & \\
  &$\mid$& bool $\;\;\;\mid\;\;\;$ int & base types & & & & \\
  &$\mid$& $\langle T_1, T_2 \rangle$ & tuple & $iv$ & ::= & 0 $\;\;\;\mid\;\;\;$ 1 $\ldots$ & \\
  &$\mid$& $T@(\oton{r})$ & pointer & & & & \\
  &$\mid$& $\text{coloring}(r)$ & region coloring & $e$ & ::= & & expressions \\
  &$\mid$& $\exists \oton{r}. T\text{ where }\Omega$ & region relationship &   &$\mid$& $bv$ $\;\;\;\mid\;\;\;$ $iv$ & constants \\
  &$\mid$& $\forall \oton{r}. (\oton{T}), \Phi, Q \rightarrow T_r$ & functions &   &$\mid$& $\langle e_1, e_2 \rangle$ $\;\;\;\mid\;\;\;$ $e$.1 $\;\;\;\mid\;\;\;$ $e$.2 & tuple \\
& & & &   &$\mid$& $id$ &  \\
$\Omega$ & ::= & $\{ \oton{\omega} \}$ & region constraints &   &$\mid$& $\text{new}\ T@r$ $\;\;\;\mid\;\;\;$ $\text{null }T@r$ $\;\;\;\mid\;\;\;$ $\text{isnull}(e)$ & \\
$\omega$ & ::= & $r_1 \leq r_2$ & subregion   &   
  &$\mid$& $\text{upregion}(e, r_1,\ldots,r_n)$ & \\
  &$\mid$& $r_1 * r_2$ & disjointness &   
  &$\mid$ & $\text{downregion}(e, r_1,\ldots,r_n)$ & \\  
& & &  & 
  &$\mid$& $\text{read}(e_1)$ $\;\mid\;$ $\text{write}(e_1, e_2)$ & memory access \\
$\Phi$ & ::= & $\{ \oton{\phi} \}$ & privileges & 
  & $\mid$ & $\text{reduce}(id, e_1, e_2)$ & \\
$\phi$ & ::= & reads$(r)$ $\;\mid\;$ writes$(r)$ $\;\mid\;$ $\text{reduces}_{id}(r)$ &  &  
  &$\mid$& $\text{newcolor}\ r$ $\;\mid\;$ $\text{color}(e_1, e_2, e_3)$ & coloring \\
& & & &  
  &   $\mid$& $e_1 + e_2$ & integer ops \\
$Q$ & ::= & $\{ \oton{q} \}$ & coherence modes  &   
       & $\mid$& $e_1 < e_2$ & comparisons \\
$q$ & ::= & atomic$(r)$ $\;\;\;\mid\;\;\;$ simult$(r)$ & &   
  &$\mid$& $\text{let}\ id : T = e_1 \text{in}\ e_2$ &  \\
& & & &   
       & $\mid$& $\text{if}\ e_1\ \text{then}\ e_2\ \text{else}\ e_3$ &  \\
$v$ & ::= & & values &   
       & $\mid$& $id[r_1, \ldots, r_n](e_1,\ldots,e_n)$ & function calls \\
  &$\mid$& $bv$ $\;\;\;\mid\;\;\;$ $iv$ & base values &   
       & $\mid$ & $\text{partition}\ r_p\text{ using }e_1\text{ as }\oton{r}\text{ in }\ e_2$ &  \\
  &$\mid$& $\langle v_1, v_2 \rangle$ & tuple & 
       & $\mid$& $\text{pack}\ e_1\ \text{as}\ T[r_1,\ldots,r_n]$ &  \\
  &$\mid$& null $\;\;\;\mid\;\;\;$ $a$ & address & 
       & $\mid$& $\text{unpack}\ e_1\ \text{as}\ id : T[r_1,\ldots,r_n]\ \text{in}\ e_2$ &  \\
  &$\mid$& $\{ (a_i, iv), \ldots \}$ & coloring & 
    & & & \\
  &$\mid$& $\langle \langle \oton{\rho}, v\rangle \rangle$ & reg. relation instance & 
   & & & \\
%$bv$ & ::= & false $\;\;\;\mid\;\;\;$ true \\
%\\
%$iv$ & ::= & 0 $\;\;\;\mid\;\;\;$ 1 $\ldots$ \\
%\\
%$e$ & ::= & & expressions \\
%  &$\mid$& $bv$ $\;\;\;\mid\;\;\;$ $iv$ & constants \\
%  &$\mid$& $\langle e_1, e_2 \rangle$ $\;\;\;\mid\;\;\;$ $e$.1 $\;\;\;\mid\;\;\;$ $e$.2 & tuple \\
%  &$\mid$& $id$ &  \\
%  &$\mid$& $\text{new}\ T@r$ $\;\;\;\mid\;\;\;$ $\text{null }T@r$ $\;\;\;\mid\;\;\;$ $\text{isnull}(e)$ & \\
%  &$\mid$& $\text{upregion}(e, r_1,\ldots,r_n)$ $\;\;\;\mid\;\;\;$ $\text{downregion}(e, r_1,\ldots,r_n)$ & \\
%  &$\mid$& $\text{read}(e_1)$ $\;\;\;\mid\;\;\;$ $\text{write}(e_1, e_2)$ $\;\;\;\mid\;\;\;$ $\text{reduce}(id, e_1, e_2)$ & memory access \\
%  &$\mid$& $\text{newcolor}\ r$ $\;\;\;\mid\;\;\;$ $\text{color}(e_1, e_2, e_3)$ & coloring operations \\
%  &$\mid$& $e_1 + e_2$ & integer operations \\
%  &$\mid$& $e_1 < e_2$ & comparison operations \\
%  &$\mid$& $\text{let}\ id : T = e_1 \text{in}\ e_2$ &  \\
%  &$\mid$& $\text{if}\ e_1\ \text{then}\ e_2\ \text{else}\ e_3$ &  \\
%  &$\mid$& $id[r_1, \ldots, r_n](e_1,\ldots,e_n)$ & function calls \\
%  &$\mid$& $\text{partition}\ r_p\text{ using }e_1\text{ as }\oton{r}\text{ in }\ e_2$ &  \\
%  &$\mid$& $\text{pack}\ e_1\ \text{as}\ T[r_1,\ldots,r_n]$ &  \\
%  &$\mid$& $\text{unpack}\ e_1\ \text{as}\ id : T[r_1,\ldots,r_n]\ \text{in}\ e_2$ &  \\
\end{tabular}
}
\caption{Core Legion}
\label{fig:langdef}
\vspace{-5mm}
\end{figure*}

%\newcommand{\infrule}[2]{\displaystyle\frac{\displaystyle\strut{#1}}{\displaystyle\strut {#2}}}
%\newcommand{\cinfrule}[3]{\parbox{14cm}{\hfil$\infrule{#1}{#2}$\hfil}\parbox{4cm}{$\,#3$\hfil}}
%\newcommand{\finfrule}[2]{\framebox{$\infrule{#1}{#2}$}}
%\newcommand{\oldfinfrule}[2]{\vspace{10pt}\framebox{$\infrule{#1}{#2}$}\vspace{10pt}}

%\newcommand{\infx}[2]{\infrule{\begin{array}{l}{#1}\end{array}}{#2}}

\section{Legion}
\label{sec:legioncore}

Figure~\ref{fig:langdef} defines Core Legion, a subset of the full Legion language
that still illustrates all of the important issues.  Types
include booleans, integers, tuples, and pointers.  Pointers
are annotated with a list of regions---a non-null pointer must point to a 
location that is contained in at least one of the regions. There is a special
type for {\em colorings}, which
are used to specify partitions of regions into subregions.
Functions in Legion are named, accept one or more arguments and
return a value of some type.  A function also declares the region
access privileges and coherence it requires.  A function may be executed
within the current task or run in parallel as a separate subtask---this decision is made
by the Legion task scheduler.  Function types are
universally quantified over all region names appearing in the type.
The final type is a region relationship, an instance of which captures a value and
one or more regions satisfying associated constraints.  A region relation instance
can be written into the heap and later read and
unpacked, giving new local names to the regions contained in
the instance.

As Legion attempts to benefit from both static and dynamic checks
to achieve performance while maintaining safety, both the type system and the operational
semantics have been extended in interesting ways from a basic expression language.  We
will describe these extensions in the next two subsections, and explain how these extensions
were chosen to preserve a straightforward proof of the soundness of the type system.

\subsection{Core Type System}
\label{subsec:coretypes}

Core Legion is explicitly typed using judgments of the form
$$\typeenv{e}{T}$$

In addition to the traditional type environment $\Gamma$, a Legion type judgment includes the
set of access privileges $\Phi$ for the logical regions in the expression as well as a set of
constraints $\Omega$ that must hold between those logical regions.

Both $\Phi$ and $\Omega$ are used in the heap access expressions: {\em read}, {\em write}, and {\em reduce}.
For a heap access to be valid, the the appropriate permission must exist for logical region(s) in the
pointer's type.  As regions are hierarchical, the exact region need not be named in $\Phi$ if permissions
exist for a logical region that is known to contain the pointer's region.  To simplify this check, we
define closure operations in Figure~\ref{fig:closure} that expand $\Omega$ into an $\Omega^*$, which is
then used to expand $\Phi$ into a $\Phi^*$ that does explicitly name every logical region for which
privileges are known to exist.

Core Legion provides no automatic pointer type conversions.  Valid pointers are created via the {\em new}
expression in specified region and invalid (i.e. {\em null}) pointers must also be typed.  Pointers can be
``upcast'' via the {\em upregion} expression, which uses the expanded constraints $\Omega^*$ to verify that
every possible region a pointer might point into is covered by at least one of the regions in the desired
pointer type.  In contrast, a ``downcast'' using the {\em downregion} expression must perform a dynamic
test to verify which region a run-time pointer value points into.  A static test similar to the one used
for {\em upregion} could be used to catch cases in which the downcast can never succeed at runtime, but we
have left it out for simplicity.

The introduction of constraints into $\Omega$ occurs through the use of the {\em partition} expression,
which makes use of a new type specific to Legion, a {\em coloring}.  A coloring is an opaque mapping from
pointers (which much point into the region being colored) to integer ``color'' values.  (For simplicity, 
Core Legion allows only an iterative construction of a coloring via a {\em newcolor} expression that generates
an empty map and a {\em color} expression which adds a new entry to an existing map, but the opacity of the
coloring allows for more efficient generation (and storage) of colorings as needed.)  The {\em partition} 
expression introduces names for subregions corresponding to each of those ``colors'', guaranteeing that each
subregion is disjoint from the other subregions and all are included in the original region.

The {\em pack} and {\em unpack} expressions allow the storage of pointers in the heap.  Logical region names
are lexically scoped and if stored in the heap as-is, can only be read within the same scope.  A region relationship
is used instead to capture the (dynamic) physical regions while preserving the statically known constraints
between those regions.  Because the {\em pack} expression is able to verify these constraints hold when the 
region relationship value is created, the {\em unpack} expression is able to reintroduce these constraints on
the (fresh) logical region names given to the contents of an unwrapped region relationship value.

Finally, the task call expression handles the aliasing of logical region names between the caller and callee and
verifies the property that the privileges held by a called task are always a subset of those held
by the caller.  In addition to being necessary for the proof of soundness, this property is critical to
enable the hierarchical scheduling model used by the Legion runtime.

\begin{comment}
\begin{figure*}
\centering{
\framebox{$\typeenv{bv}{bool}$}
\framebox{$\typeenv{iv}{int}$}
\finfrule
{\begin{array}{l}
\typeenvx e_1 : T_1 \\
\typeenvx e_2 : T_2
\end{array}}
{\typeenvx \langle e_1, e_2 \rangle : \langle T_1, T_2 \rangle}
\finfrule{\typeenvx e : \langle T_1,T_2 \rangle}{\typeenvx e\text{.1}\ : T_1}
\finfrule{\typeenvx e : \langle T_1,T_2 \rangle}{\typeenvx e\text{.2}\ : T_2}
\finfrule{\Gamma(id) = T}{\typeenvx id : T}
\framebox{$\typeenvx \text{null }T@r : T@r$}
\framebox{$\typeenvx \text{new }T@r : T@r$}
\finfrule{\typeenvx e : T@(\oton{r})}{\typeenvx \text{isnull}(e) : bool}
\finfrule
{\begin{array}{l}
\typeenvx e : T@(r'_1, \ldots r'_k) \\
\forall i. \exists j, r'_i \leq r_j \in \Omega^* \\
\end{array}}
{\typeenvx upregion(e,\oton{r}) : T@(\oton{r})}
\finfrule
{\begin{array}{l}
\typeenvx e : T@(r'_1, \ldots r'_k) \\
\forall j. \exists i, r_j \leq r'_i \in \Omega^* \\
\end{array}}
{\typeenvx downregion(e,\oton{r}) : T@(\oton{r})}
\finfrule
{\begin{array}{l}
\typeenvx e_1 : T@(\oton{r}) \\
\forall i, reads(r_i) \in \Phi^*\end{array}}
{\typeenvx \text{read}(e_1) : T}
\finfrule
{\begin{array}{l}
\typeenvx e_1 : T@(\oton{r}) \\
\typeenvx e_2 : T \\
\forall i, writes(r_i) \in \Phi^*
\end{array}}
{\typeenvx \text{write}(e_1, e_2) : T@(\oton{r})}
\finfrule
{\begin{array}{l}
\Gamma(id) = (T_1, T_2), \emptyset, \emptyset \rightarrow T_1 \\
\typeenvx e_1 : T_1@(\oton{r}) \\
\typeenvx e_2 : T_2 \\
\forall i, reduces_{id}(r_i) \in \Phi^*
\end{array}}
{\typeenvx \text{reduce}(id, e_1, e_2) : T_1@(\oton{r})}
\framebox{$\typeenvx \text{newcolor }r : \text{coloring}(r)$}
\finfrule{\begin{array}{l}
\typeenvx e_1 : \text{coloring}(r) \\
\typeenvx e_2 : T@r \\
\typeenvx e_3 : int
\end{array}}
{\typeenvx \text{color}(e_1, e_2, e_3) : \text{coloring}(r)}
\finfrule{\begin{array}{l}\typeenvx e_1 : int \\ \typeenvx e_2 : int\end{array}}{\typeenvx e_1 + e_2 : int}
\finfrule{\begin{array}{l}\typeenvx e_1 : int \\ \typeenvx e_2 : int\end{array}}{\typeenvx e_1 < e_2 : bool}
\finfrule{\begin{array}{l}
\typeenvx e_1 : T_1 \\
\typeenvx[G={\Gamma[id/T_1]}] e_2 : T_2
\end{array}}
{\typeenvx : \text{let}\ id : T_1 \text{in}\ e_2 : T_2}
\finfrule{\begin{array}{l}\typeenvx e_1 : bool \\ \typeenvx e_2 : T \\ \typeenvx e_3 : T\end{array}}{\typeenvx \text{if}\ e_1\ \text{then}\ e_2\ \text{else}\ e_3 : T}
\finfrule{
\begin{array}{l}
\Gamma(id) = \forall r'_1, \ldots r'_k.(\oton{T}),\Phi', Q' \rightarrow T_r \\
\typeenvx e_i : T_i[r_1/r'_1,\ldots,r_k/r'_k] \\
\Phi'[r_1/r'_1,\ldots,r_k/r'_k] \subseteq \Phi^*
\end{array}}
{\typeenvx id[\otok{k}{r}](\oton{e}) : T_r[r_1/r'_1,\ldots,r_k/r'_k]}
\finfrule{
\begin{array}{l}
\typeenvx e_1 : \text{coloring}(r_p) \\
\Omega' = \Omega \wedge \bigwedge_{i \in [1,k]} r_i \leq r_p \wedge \bigwedge_{1 \leq i < j \leq k} r_i * r_j \\
\typeenvx[O=\Omega'] e_2 : T \\
\{ \oton{r} \} \cap \textit{regions\_of}(\Gamma, T) = \emptyset
\end{array}}
{\typeenvx \text{partition}\ r_p\text{ using }e_1\text{ as }\otok{k}{r}\text{ in }e_2 : T}
\finfrule{
\begin{array}{l}
T_1 = \exists r'_1, \ldots r'_n.\ T_2\text{ where }\Omega_1 \\
\Omega_1[r_1/r'_1,\ldots,r_k/r'_k] \subseteq \Omega^* \\
\typeenvx e_1 : T_2[r_1/r'_1,\ldots,r_k/r'_k]
\end{array}}
{\typeenvx \text{pack}\ e_1\ \text{as}\ T_1[\otok{k}{r}] : T_1}
\finfrule{
\begin{array}{l}
T_1 = \exists r'_1, \ldots, r'_n.\ T_2\text{ where }\Omega_1 \\
\typeenvx e_1 : T_1 \\
\Gamma' = \Gamma[T_2[r_1/r'_1,\ldots,r_k/r'_k] / id] \\
\Omega' = \Omega \cup \Omega_1[r_1/r'_1,\ldots,r_k/r'_k] \\
\typeenvx[G=\Gamma',O=\Omega'] e_2 : T_3 \\
\{ \oton{r} \} \cap \textit{regions\_of}(\Gamma, T_1, T_3) = \emptyset
\end{array}}
{\typeenvx \text{unpack}\ e_1\ \text{as}\ id : T_1[\otok{k}{r}] \text{in}\ e_2 : T_3}
\finfrule{
\begin{array}{l}
\text{for }1 \leq i \leq p, \\
\Gamma(id_i) = \forall r_{i1}, \ldots r_{ik_i}. (T_{i1}, \ldots, T_{in_i}), \Phi_i, Q_i \rightarrow T_{ir} \\
\Gamma_i = \Gamma[a_{i1}/T_{i1}, \ldots, a_{in_i}/T_{in_i}] \\
\typeenv[G={\Gamma_i},P={\Phi_i},O=\emptyset]{e_i}{T_{ir}}
\end{array}}
{ 
\begin{array}{l@{ }l}
\vdash \{ & \text{function }id_1[r_{11}, \ldots, r_{1k_1}]( a_{11} : T_{11}, \ldots a_{1n_1} : T_{1n_1} ), \Phi_1, Q_1 : T_{1r} : e_1, \\
          & \ldots \\
          & \text{function }id_p[r_{p1}, \ldots, r_{pk_1}]( a_{p1} : T_{p1}, \ldots a_{pn_p} : T_{pn_p} ), \Phi_p, Q_p : T_{pr} : e_p \} : \bullet
\end{array} }
}
\caption{Legion Core Type System}
\label{fig:types}
\end{figure*}
\end{comment}

\begin{figure*}
\begin{adjustwidth}{-4em}{-4em}
\begin{center}
% Row 1: bool, int, tuple1, tuple2
\begin{minipage}{\linewidth}
%\centering
\begin{tabular}{m{4cm}m{3.5cm}m{5cm}m{5cm}}
\infax[T-Bool]{\typeenv{bv}{bool}} & 
\infax[T-Int]{\typeenv{iv}{int}} & 
\infrule[T-Tuple1]{\typeenvx e : \langle T_1,T_2 \rangle}{\typeenvx e\text{.1}\ : T_1} & 
\infrule[T-Tuple2]{\typeenvx e : \langle T_1,T_2 \rangle}{\typeenvx e\text{.2}\ : T_2} 
\end{tabular}
\end{minipage}
% Row 2:  var, null, isnull, maketuple
\begin{minipage}{\linewidth}
\vspace{-0.4cm}
%\centering
\begin{tabular}{m{3cm}m{3cm}m{5cm}m{6cm}}
\infrule[T-Var]{\Gamma(id) = T}{\typeenvx id : T} &
\infax[T-Null]{\typeenvx \text{null }T@r : T@r} &
\infrule[T-IsNull]{\typeenvx e : T@(\oton{r})}{\typeenvx \text{isnull}(e) : bool} &
\infrule[T-MakeTuple]{\typeenvx e_1 : T_1 \andalso \typeenvx e_2 : T_2}{\typeenvx \langle e_1, e_2 \rangle : \langle T_1, T_2 \rangle}
\end{tabular}
\end{minipage}
% Row 3: new, newcolor, coloring
\begin{minipage}{\linewidth}
\vspace{-0.6cm}
%\centering
\begin{tabular}{m{4cm}m{5cm}m{9cm}}
\infax[T-New]{\typeenvx \text{new }T@r : T@r} &
\infax[T-Newcolor]{\typeenvx \text{newcolor }r : \text{coloring}(r)} &
\infrule[T-Color]{\typeenvx e_1 : \text{coloring}(r) \andalso \typeenvx e_2 : T@r \andalso \typeenvx e_3 : int}{\typeenvx \text{color}(e_1, e_2, e_3) : \text{coloring}(r)}
\end{tabular}
\end{minipage}
% Row 4: let, add, compare
\begin{minipage}{\linewidth}
\vspace{-0.7cm}
%\centering
\begin{tabular}{m{6cm}m{5cm}m{6cm}}
\infrule[T-Let]{\typeenvx e_1 : T_1 \\ \typeenvx[G={\Gamma[id/T_1]}] e_2 : T_2}{\typeenvx : \text{let}\ id : T_1 \text{in}\ e_2 : T_2} &
\infrule[T-Add]{\typeenvx e_1 : int \\ \typeenvx e_2 : int}{\typeenvx e_1 + e_2 : int} &
\infrule[T-Compare]{\typeenvx e_1 : int \\ \typeenvx e_2 : int}{\typeenvx e_1 < e_2 : bool}
\end{tabular}
\end{minipage}
% Row 5: upregion, downregion
\begin{minipage}{\linewidth}
\vspace{-0.4cm}
\begin{tabular}{m{9cm}m{10cm}}
\infrule[T-UpRgn]{\typeenvx e : T@(r'_1, \ldots r'_k) \andalso \forall i. \exists j, r'_i \leq r_j \in \Omega^*}{\typeenvx upregion(e,\oton{r}) : T@(\oton{r})} &
\infrule[T-DownRgn]{\typeenvx e : T@(r'_1, \ldots r'_k)
% \andalso \forall j. \exists i, r_j \leq r'_i \in \Omega^*
}{\typeenvx downregion(e,\oton{r}) : T@(\oton{r})}
\end{tabular}
\end{minipage}
% Row 6: read, write, reduce
\begin{minipage}{\linewidth}
\vspace{-0.3cm}
\begin{tabular}{m{5cm}m{5cm}m{8cm}}
\infrule[T-Read]{\typeenvx e_1 : T@(\oton{r}) \\ \forall i, reads(r_i) \in \Phi^*}{\typeenvx \text{read}(e_1) : T} &
\infrule[T-Write]{\typeenvx e_1 : T@(\oton{r}) \\ \typeenvx e_2 : T \\ \forall i, writes(r_i) \in \Phi^*}{\typeenvx \text{write}(e_1, e_2) : T@(\oton{r})} &
\infrule[T-Reduce]{\Gamma(id) = (T_1, T_2), \emptyset, \emptyset \rightarrow T_1 \andalso \typeenvx e_2 : T_2 \\
 \typeenvx e_1 : T_1@(\oton{r}) \andalso \forall i, reduces_{id}(r_i) \in \Phi^*}{\typeenvx \text{reduce}(id, e_1, e_2) : T_1@(\oton{r})}
\end{tabular}
\end{minipage}
% Row 7: pack, if-else, task call
\begin{minipage}{\linewidth}
\vspace{-0.6cm}
\begin{tabular}{m{5cm}m{5cm}m{8cm}}
\infrule[T-Pack]{T_1 = \exists r'_1, \ldots r'_n.\ T_2\text{ where }\Omega_1 \\ \Omega_1[r_1/r'_1,\ldots,r_k/r'_k] \subseteq \Omega^* \\ \typeenvx e_1 : T_2[r_1/r'_1,\ldots,r_k/r'_k]}{\typeenvx \text{pack}\ e_1\ \text{as}\ T_1[\otok{k}{r}] : T_1} &
\infrule[T-IfElse]{\typeenvx e_1 : bool \\ \typeenvx e_2 : T \\ \typeenvx e_3 : T}{\typeenvx \text{if}\ e_1\ \text{then}\ e_2\ \text{else}\ e_3 : T} &
\infrule[T-Call]{\Gamma(id) = \forall r'_1, \ldots r'_k.(\oton{T}),\Phi', Q' \rightarrow T_r \\ \typeenvx e_i : T_i[r_1/r'_1,\ldots,r_k/r'_k] \\ \Phi'[r_1/r'_1,\ldots,r_k/r'_k] \subseteq \Phi^*}{\typeenvx id[\otok{k}{r}](\oton{e}) : T_r[r_1/r'_1,\ldots,r_k/r'_k]}
\end{tabular}
\end{minipage}
% Row 8: unpack, partition
\begin{minipage}{\linewidth}
\vspace{-0.7cm}
\begin{tabular}{m{10cm}m{8cm}}
\infrule[T-Unpack]{T_1 = \exists r'_1, \ldots, r'_n.\ T_2\text{ where }\Omega_1 \andalso \typeenvx e_1 : T_1 \\
  \Gamma' = \Gamma[T_2[r_1/r'_1,\ldots,r_k/r'_k] / id] \andalso \Omega' = \Omega \cup \Omega_1[r_1/r'_1,\ldots,r_k/r'_k] \\
  \typeenvx[G=\Gamma',O=\Omega'] e_2 : T_3 \andalso \{ \oton{r} \} \cap \textit{regions\_of}(\Gamma, T_1, T_3) = \emptyset}
  {\typeenvx \text{unpack}\ e_1\ \text{as}\ id : T_1[\otok{k}{r}] \text{in}\ e_2 : T_3} &
\infrule[T-Part]{\typeenvx e_1 : \text{coloring}(r_p) \\ \Omega' = \Omega \wedge \bigwedge_{i \in [1,k]} r_i \leq r_p \wedge \bigwedge_{1 \leq i < j \leq k} r_i * r_j \\ \typeenvx[O=\Omega'] e_2 : T \\ \{ \oton{r} \} \cap \textit{regions\_of}(\Gamma, T) = \emptyset}
  {\typeenvx \text{partition}\ r_p\text{ using }e_1\text{ as }\otok{k}{r}\text{ in }e_2 : T}
\end{tabular}
\end{minipage}
% Row 9: program
\begin{minipage}{\linewidth}
\vspace{-0.5cm}
\infrule[T-Program]{\text{for }1 \leq i \leq p, \\
  \Gamma(id_i) = \forall r_{i1}, \ldots r_{ik_i}. (T_{i1}, \ldots, T_{in_i}), \Phi_i, Q_i \rightarrow T_{ir} \andalso
  \Gamma_i = \Gamma[a_{i1}/T_{i1}, \ldots, a_{in_i}/T_{in_i}] \andalso
  \typeenv[G={\Gamma_i},P={\Phi_i},O=\emptyset]{e_i}{T_{ir}}}
  {\begin{array}{@{}l@{}l@{}}
   \vdash \{ & \text{function }id_1[r_{11}, \ldots, r_{1k_1}]( a_{11} : T_{11}, \ldots a_{1n_1} : T_{1n_1} ), \Phi_1, Q_1 : T_{1r} : e_1, \\
           & \ldots \\
           & \text{function }id_p[r_{p1}, \ldots, r_{pk_1}]( a_{p1} : T_{p1}, \ldots a_{pn_p} : T_{pn_p} ), \Phi_p, Q_p : T_{pr} : e_p \} : \bullet
   \end{array}
  }
\end{minipage}
\end{center}
\end{adjustwidth}
\caption{Legion Core Type System}
\vspace{-5mm}
\label{fig:types}
\end{figure*}

\begin{figure}
\centering{
$\begin{array}{l}
\Omega \subseteq \Omega^* \\
r_i \leq r_j \in \Omega^*  \Rightarrow r_i \leq r_i \in \Omega^*\wedge r_j \leq r_j \in \Omega^* \\
r_i \leq r_j \in \Omega^* \wedge r_j \leq r_k \in \Omega^* \Rightarrow r_i \leq r_k \in \Omega^* \\
r_i \leq r_j \in \Omega^* \wedge r_j * r_k \in \Omega^* \Rightarrow r_i * r_k \in \Omega^* \\
r_i * r_j \in \Omega^* \Rightarrow r_j * r_i \in \Omega^* \\
\\
\Phi \subseteq \Phi^* \\
r_i \leq r_j \in \Omega^* \wedge reads(r_j) \in \Phi^* \Rightarrow reads(r_i) \in \Phi^* \\
r_i \leq r_j \in \Omega^* \wedge writes(r_j) \in \Phi^* \Rightarrow writes(r_i) \in \Phi^* \\
r_i \leq r_j \in \Omega^* \wedge reduces_{id}(r_j) \in \Phi^* \Rightarrow reduces_{id}(r_i) \in \Phi^* \\
reads(r) \in \Phi^* \wedge writes(r) \in \Phi^* \Rightarrow reduces_{id}(r) \in \Phi^* \\
\ \ \ \mbox{for every function identifier $id$}
\end{array}$
}
\caption{Privilege and Constraint Closure}
\vspace{-5mm}
\label{fig:closure}
\end{figure}

\subsection{Operational Semantics}
\label{subsec:opsemantics}

Core Legion's operational semantics rules have the following form:
$$\opsenv{e}{v}{E}$$
and specify that, given a certain environment, the evaluation of expression $e$ yields a value $v$ and a
{\em dynamic memory trace} $E$ which is a sequence of all heap operations (reads, writes, reductions) performed
during the evaluation, including their location and the value read or written.

In addition to the usual value mappings for local variables $L$ and store (i.e. heap) locations $S$, the Legion
operational semantics environments includes an immutable heap typing $H$ that maps locations to types, and a region
mapping $M$ that maps logical regions $r_i$ to physical regions $\rho_i$, which are sets of concrete memory
locations.

The final element of the environment is the {\em clobber set} $C$.  Our goal is to show that parallel Legion
programs can
be scheduled in a hierarchical (and therefore scalable) fashion, we require a formulation of operational semantics
that is both parallel and hierarchical.  Because Legion allows constrained nondeterminism (in the order in which
reductions are applied and in cases of relaxed coherence), it is possible for the heap accesses performed by
one expression's evaluation to observe interference from other concurrent evaluations.  The traditional way of
handling this in operational semantics \cite{XYZ} is to use a top-down approach with small-step semantics and
a global view of all
partially-evaluated expressions.  Rules are specified for which expression(s) are valid choices for the next small
step of execution.  This approach has the benefit of being constructive but the implicit global ``scheduler'' is
difficult to map into a hierarchical one in which decisions must necessarily be made with limited information.

Instead we use a bottom-up approach with large-step semantics in which each expression is evaluated with limited 
information about the overall environment.  The information consists of the initial state of the heap $S$, and a
set of memory locations that might be modified by other concurrent evaluations.  This is the clobber set $C$,
and is used to relax the constraints the evaluation of an expression.  Whereas the requirement for locations not
in the clobber set is the usual one of {\em consistency} (i.e. a read from a location observes the effect of all 
previous modifications applied in order), the value read from a location in the clobber set may be hypothesized
to be any value at all.  The validation of these hypotheses is deferred until all potentially-concurrent
modifications to a location can be observed (i.e. the evaluation of a parent expression whose clobber set does
not include the location) and a consistent interleaving of the subexpressions' memory traces can be determined.
With this formulation, the criteria for when a hierarchical scheduler may execute subexpressions in parallel can be
made clear, but they are no longer constructive.  Instead, we will have to show that the scheduling algorithms
used by the Legion runtime satisfy these constraints, guaranteeing the soundness of the Legion programming model.

The complete operational semantics rules can be found in \cite{LegionTypes12} - we show the most interesting ones
in Figure~\ref{fig:semantics}.  The rules for the {\em read}, {\em write}, and {\em reduce} show how dynamic memory
traces are constructed and how the result of a read expression is relaxed when the location falls within the
clobber set.  Additionally, the write and reduce operations, with their two subexpressions, demonstrate how the
traces of subexpressions are interleaved within the environment (and clobber set) of the parent expression.
(A formal definition of the {\em valid\_interleave} predicate can be found in Figure~\ref{fig:validinterleave}, and
will be discussed in Section~\ref{sec:coherence}.)

The first use of the region mapping $M$ occurs in the {\em new} and {\em downregion} expressions.  The new
expression is constrained to select a location (with the right heap typing) from the set that the specified logical
region has been mapped to.  (Although one would expect the new expression to also return a location that is not
currently in use, our soundness result does not require this additional constraint, so we have omitted it for
simplicity.)  Similarly, the downregion expression checks whether a location is within the set of locations the
logical region(s) have been mapped to, returning {\em null} if not.  As discussed above, the corresponding 
{\em upregion} expression checks are performed statically.

The general form of a coloring being an abitrary mapping of locations to ``colors'' (integers) is shown in the
operational semantics rules for the {\em newcolor} and {\em color} expressions.  The color expression accepts an
existing coloring and returns one in which the specified location is given the specified color, replacing an
existing coloring for that location (if present).  The behavior of the newcolor expression is a bit trickier.
Since Legion supports the {\em partition-then-allocate} model in which the {\em new} expression may be called
on subregions, each subregion that results from a partitioning may need an arbitrary number of locations for which
the program does not know the name at partitioning time.  The semantics for the newcolor expression allow this while
guaranteeing that any explicit colorings performed by the program are honored.

The semantics for the {\em pack} and {\em unpack} expressions are straightforward.  Packing a region relationship
is just a matter of capturing the physical regions to which the logical regions are currently mapped, whereas 
unpacking takes those physical regions and gives them fresh logical names within the evaluation of the body.

Finally, although the semantics for calls to subtasks appear complicated at first glance, the bulk of the rules
are just handling the evaluation of each actual argument expression and the creation of the called subtask's 
environment (with potentially different names for logical regions).  The key difference in Legion task calls is the
handling of relaxed coherence.  Any location that falls within
a logical region whose coherence has been relaxed (via {\em atomic} or {\em simult}) is added to the clobber set
$C'$, allowing non-deterministic evaluation within the subtask with respect to those locations.  All actual accesses
to those locations within the resulting memory trace ($E_{n+1}$) are marked with the corresponding coherence mode,
allowing the {\em valid\_interleave} check within the caller's environment to verify the consistency of the overall
memory trace.

\begin{figure*}
\centering{
$
\begin{array}{@{}l@{}}
\begin{array}{@{}l@{\hspace{-0.25in}}l@{}} 
\begin{array}{@{}lll}
apply(S, []) & = & S \\
apply(S, E \dplus [ read(l, c, v) ]) & = & apply(S, E) \\
apply(S, E \dplus [ write(l, c, v) ]) & = & apply(S, E)[v/l] \\
apply(S, E \dplus [ reduce_{id}(l, c, v) ]) & = & S'[id(S'(l), v)/l], \\
& & \text{ where } S' = apply(S, E)
\end{array} &
\begin{array}{@{}ll}
mark\_coh([], \hat Q) & = [] \\
mark\_coh([ op(l, c, v) ] \dplus E, \hat Q) & = [ op(l, c', v) ] \dplus mark\_coh(E, \hat Q), \\
\multicolumn{2}{@{}l}{ \hspace{1.0in} \text{ where } c' =
\begin{cases}
simult, & \text{if }\exists \rho. l \in \rho \wedge simult(\rho) \in \hat Q \\
atomic, & \text{if }\exists \rho. l \in \rho \wedge atomic(\rho) \in \hat Q \\
excl, & \text{otherwise}
\end{cases}}
\end{array}
\end{array} \\
\begin{array}{@{}lll}
any\_interleave([], [], \ldots, []) & = & true \\
any\_interleave([ \epsilon ] \dplus E', E_1, \ldots, [ \epsilon ] \dplus E_i, \ldots, E_n) & = & any\_interleave(E', E_1, \ldots, E_i, \ldots, E_n) \\
valid\_interleave(S, C, E', \oton{E}) & \Rightarrow & any\_interleave(E', \oton{E}) \\
\end{array}
\end{array}
$}
\caption{Operational Semantics Helper Functions}
\label{fig:opsemfns}
\vspace{-5mm}
\end{figure*}

\begin{comment}
\begin{figure*}
\centering{\small
\framebox{$\opsenvx bv \mapsto bv, []$}
\framebox{$\opsenvx iv \mapsto iv, []$}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S' = apply(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \langle e_1, e_2 \rangle \mapsto \langle v_1, v_2 \rangle, E'}
\finfrule
{\opsenvx e \mapsto \langle v_1, v_2 \rangle, E}
{\opsenvx e\text{.1} \mapsto v_1, E} \hspace{1cm}
\finfrule
{\opsenvx e \mapsto \langle v_1, v_2 \rangle, E}
{\opsenvx e\text{.2} \mapsto v_2, E}
\finfrule
{L(id) = v}
{\opsenvx id \mapsto v, []}
\framebox{$\opsenvx \text{null }T@r \mapsto null, []$}
\finfrule
{\begin{array}{l}
l \in M(r) \\
H(l) = M \llbracket T \rrbracket
\end{array}}
{\opsenvx \text{new }T@r \mapsto l, []}
\finfrule
{\opsenvx e \mapsto l, E}
{\opsenvx \text{isnull}(e) \mapsto \textit{false}, E}
\finfrule
{\opsenvx e \mapsto null, E}
{\opsenvx \text{isnull}(e) \mapsto true, E}
\finfrule
{\opsenvx e \mapsto v, E}
{\opsenvx \text{upregion}(e, \oton{r}) \mapsto v, E}
\finfrule
{\begin{array}{l}
\opsenvx e \mapsto l, E \\
v = \begin{cases}
l, & \text{if $\exists i, l \in M(r_i)$}. \\
null, & \text{otherwise}.
\end{cases}
\end{array}}
{\opsenvx \text{downregion}(e, \oton{r}) \mapsto v, E}
\finfrule
{\begin{array}{l}
\opsenvx e \mapsto l, E \\
S' = \text{apply}(S, E) \\
v = \begin{cases}
S'(l), & \text{if } l \not\in C \\
v' : H(l), & \text{otherwise}
\end{cases}
\end{array}}
{\opsenvx \text{read}(e) \mapsto v, E \dplus [ read(l, excl, v) ]}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto l, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{write}(e_1, e_2) \mapsto l, E' \dplus [ write(l, excl, v) ]}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto l, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{reduce}(id, e_1, e_2) \mapsto l, E' \dplus [ reduce_{id}(l, excl, v) ]}
\finfrule{
\begin{array}{l@{}l}
K = \{ (l_1, iv_1), & \ldots, (l_p, v_p) \}, \text{ where } \\
& (\forall i \in [1,p]. l_i \in M(r)) \wedge \\
& (\forall i,j \in [1,p]. l_i \not= l_j)
\end{array}
}
{\opsenvx \text{newcolor }r \mapsto K, []}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto K, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto l, E_2 \\
S'' = \text{apply}(S', E_2) \\
\opsenvx[S=S''] e_3 \mapsto v, E_3 \\
K' = \{ (l,v) \} \cup \{ (l_i,v_i) : (l_i,v_i) \in K \wedge l \not= l_i \} \\
valid\_interleave(S, C, E', E_1, E_2, E_3)
\end{array}}
{\opsenvx \text{color}(e_1, e_2, e_3) \mapsto K', E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\
v' = v_1 + v_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx e_1 + e_2 \mapsto v', E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\
v' = \begin{cases}
true, & \text{if $v_1 < v_2$}. \\
\textit{false}, & \text{otherwise}.
\end{cases} \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx e_1 < e_2 \mapsto v', E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
L' = L[v_1/id] \\
S' = \text{apply}(S, E_1) \\
\opsenvx[L=L',S=S'] e_2 \mapsto v_2, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{let }id : T = e_1\text{ in }e_2 \mapsto v_2, E'}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto true, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_2 \mapsto v_2, E_2
\end{array}}
{\opsenvx \text{if }e_1\text{ then }e_2\text{ else }e_3 \mapsto v_2, E_1 \dplus E_2}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto \textit{false}, E_1 \\
S' = \text{apply}(S, E_1) \\
\opsenvx[S=S'] e_3 \mapsto v_3, E_3
\end{array}}
{\opsenvx \text{if }e_1\text{ then }e_2\text{ else }e_3 \mapsto v_3, E_1 \dplus E_3}
\finfrule
{\begin{array}{l}
\opsenvx e_1 \mapsto v_1, E_1 \\
S_1 = \text{apply}(S, E_1) \\
\opsenvx e_2 \mapsto v_2, E_2 \\
\ldots \\
S_n = \text{apply}(S_{n-1}, E_n) \\
valid\_interleave(S, C, E', \oton{E})
\vspace{1.5mm} \\
\text{function }id[\otok{k}{r'}](a_1 : T_1, \ldots, a_n : T_n), \Phi', Q' : T_r = e_{n+1} \\
M' = \{ (r'_1, M(r_1)), \ldots (r'_k, M(r_k)) \} \\
L' = \{ (a_1, v_1), \ldots, (a_n, v_n) \} \\
S' = \text{apply}(S, E') \\
C' = C \cup \{ l : \exists \rho. atomic(\rho) \in M' \llbracket Q' \rrbracket \vee simult(\rho) \in M' \llbracket Q' \rrbracket \} \\
\opsenvx[M=M',L=L',S=S'] e_{n+1} \mapsto v_{n+1}, E_{n+1}
\vspace{1.5mm} \\
E'_{n+1} = mark\_coherence(E_{n+1}, M' \llbracket Q' \rrbracket) \\
valid\_interleave(S, C, E'', E', E_{n+1})
\end{array}}
{\opsenvx id[\otok{k}{r}](\oton{e}) \mapsto v_{n+1}, E''}
\finfrule{
\begin{array}{l}
\opsenv{e_1}{K}{E_1} \\
\rho_i = \{ l : (l, i) \in K \}, \text{ for } 1 \leq i \leq k \\
M' = M[\rho_1/r_1, \ldots, \rho_k/r_k] \\
S' = \text{apply}(S, E_1) \\
\opsenvx[M=M',S=S'] e_2 \mapsto v, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{partition}\ r_p\text{ using }e_1\text{ as }\otok{k}{r}\text{ in }e_2 \mapsto v, E'}
\finfrule{
\begin{array}{l}
\opsenvx e_1 \mapsto v, E \\
\rho_i = M[r_i], \text{ for } 1 \leq i \leq k \\
v' = \langle \langle \otok{k}{\rho}, v \rangle \rangle
\end{array}}
{\opsenvx \text{pack}\ e_1\ \text{as}\ T_1[\otok{k}{r}] \mapsto v', E}
\finfrule{
\begin{array}{l}
\opsenvx e_1 \mapsto \langle \langle \otok{k}{\rho} , v_1 \rangle \rangle, E_1 \\
M' = M[\rho_1/r_1, \ldots, \rho_k/r_k] \\
L' = L[v_1/id] \\
S' = \text{apply}(S, E_1) \\
\opsenvx[M=M',L=L',S=S'] e_2 \mapsto v_2, E_2 \\
valid\_interleave(S, C, E', E_1, E_2)
\end{array}}
{\opsenvx \text{unpack}\ e_1\ \text{as}\ id : T_1[\otok{k}{r}] \text{in}\ e_2 \mapsto v_2, E' }
}
\caption{Legion Core Operational Semantics}
\label{fig:semantics}
\end{figure*}
\end{comment}

\begin{figure*}
\begin{adjustwidth}{-4em}{-4em}
\begin{center}
% Row 1: bool, int, val
\begin{minipage}{\linewidth}
\begin{tabular}{m{6cm}m{6cm}m{6cm}}
\infax[E-Bool]{\opsenvx bv \mapsto bv, []} &
\infax[E-Int]{\opsenvx iv \mapsto iv, []} &
\infax[E-Null]{\opsenvx \text{null }T@r \mapsto null, []} 
\end{tabular}
\end{minipage}
% Row 2: tuple1, tuple2, make tuple
\begin{minipage}{\linewidth}
\vspace{-0.6cm}
\begin{tabular}{m{9cm}m{4.5cm}m{4.5cm}}
\infrule[E-MakeTuple]{\opsenvx e_1 \mapsto v_1, E_1 \andalso S' = apply(S, E_1) \\
  \opsenvx[S=S'] e_2 \mapsto v_2, E_2 \andalso valid\_interleave(S, C, E', E_1, E_2)}
  {\opsenvx \langle e_1, e_2 \rangle \mapsto \langle v_1, v_2 \rangle, E'} &
\infrule[E-Tuple1]{\opsenvx e \mapsto \langle v_1, v_2 \rangle, E}{\opsenvx e\text{.1} \mapsto v_1, E} &
\infrule[E-Tuple2]{\opsenvx e \mapsto \langle v_1, v_2 \rangle, E}{\opsenvx e\text{.2} \mapsto v_2, E}
\end{tabular}
\end{minipage}
% Row 3: new, null, isnull, isnull
\begin{minipage}{\linewidth}
\vspace{-0.6cm}
\begin{tabular}{m{4cm}m{4.5cm}m{5cm}m{5cm}}
\infrule[E-New]{l \in M(r) \\ H(l) = M \llbracket T \rrbracket}{\opsenvx \text{new }T@r \mapsto l, []} &
\infrule[E-Var]{L(id) = v}{\opsenvx id \mapsto v, []} &
\infrule[E-IsNull-F]{\opsenvx e \mapsto l, E}{\opsenvx \text{isnull}(e) \mapsto \textit{false}, E} &
\infrule[E-IsNull-T]{\opsenvx e \mapsto null, E}{\opsenvx \text{isnull}(e) \mapsto true, E}
\end{tabular}
\end{minipage}
% Row 4: let, add, compare
\begin{minipage}{\linewidth}
\vspace{-0.7cm}
\begin{tabular}{m{6cm}m{6cm}m{6cm}}
\infrule[E-Let]{\opsenvx e_1 \mapsto v_1, E_1 \\ L' = L[v_1/id] \\ S' = \text{apply}(S, E_1) \\ \opsenvx[L=L',S=S'] e_2 \mapsto v_2, E_2 \\ valid\_interleave(S, C, E', E_1, E_2)}{\opsenvx \text{let }id : T = e_1\text{ in }e_2 \mapsto v_2, E'} &
\infrule[E-Add]{\opsenvx e_1 \mapsto v_1, E_1 \\ S' = \text{apply}(S, E_1) \\ \opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\ v' = v_1 + v_2 \\ valid\_interleave(S, C, E', E_1, E_2)}{\opsenvx e_1 + e_2 \mapsto v', E'} &
\infrule[E-Compare]{\opsenvx e_1 \mapsto v_1, E_1 \\ S' = \text{apply}(S, E_1) \\ \opsenvx[S=S'] e_2 \mapsto v_2, E_2 \\ v' = \begin{cases} true, & \text{if $v_1 < v_2$}. \\ \textit{false}, & \text{otherwise}. \end{cases} \\ valid\_interleave(S, C, E', E_1, E_2)}{\opsenvx e_1 < e_2 \mapsto v', E'}
\end{tabular}
\end{minipage}
% Row 5: if-else, if-else, new color
\begin{minipage}{\linewidth}
\vspace{-0.7cm}
\begin{tabular}{m{6.5cm}m{6.5cm}m{6cm}}
\infrule[E-IfElse-T]{\opsenvx e_1 \mapsto true, E_1 \\ S' = \text{apply}(S, E_1) \\ \opsenvx[S=S'] e_2 \mapsto v_2, E_2}{\opsenvx \text{if }e_1\text{ then }e_2\text{ else }e_3 \mapsto v_2, E_1 \dplus E_2} &
\infrule[E-IfElse-F]{\opsenvx e_1 \mapsto \textit{false}, E_1 \\ S' = \text{apply}(S, E_1) \\ \opsenvx[S=S'] e_3 \mapsto v_3, E_3}{\opsenvx \text{if }e_1\text{ then }e_2\text{ else }e_3 \mapsto v_3, E_1 \dplus E_3} &
\infrule[E-Newcolor]{K = \{ (l_1, iv_1), \ldots, (l_p, iv_p) \}, \text{ where } \\ (\forall i \in [1,p]. l_i \in M(r)) \wedge (\forall i,j \in [1,p]. l_i \not= l_j)}{\opsenvx \text{newcolor }r \mapsto K, []}
\end{tabular}
\end{minipage}
% Row 6: partition, color
\begin{minipage}{\linewidth}
\vspace{-0.6cm}
\begin{tabular}{m{8.5cm}m{10.5cm}}
\infrule[E-Part]{\opsenv{e_1}{K}{E_1} \andalso \rho_i = \{ l : (l, i) \in K \}, \text{ for } 1 \leq i \leq k \\
  M' = M[\rho_1/r_1, \ldots, \rho_k/r_k] \andalso S' = \text{apply}(S, E_1) \\
  \opsenvx[M=M',S=S'] e_2 \mapsto v, E_2 \andalso valid\_interleave(S, C, E', E_1, E_2)}
  {\opsenvx \text{partition}\ r_p\text{ using }e_1\text{ as }\otok{k}{r}\text{ in }e_2 \mapsto v, E'} &
\infrule[E-Color]{\opsenvx e_1 \mapsto K, E_1 \andalso S' = \text{apply}(S, E_1) \\
  \opsenvx[S=S'] e_2 \mapsto l, E_2 \andalso S'' = \text{apply}(S', E_2) \\
  \opsenvx[S=S''] e_3 \mapsto v, E_3 \\
  K' = \{ (l,v) \} \cup \{ (l_i,v_i) : (l_i,v_i) \in K \wedge l \not= l_i \} \\
  valid\_interleave(S, C, E', E_1, E_2, E_3)}
  {\opsenvx \text{color}(e_1, e_2, e_3) \mapsto K', E'} 
\end{tabular}
\end{minipage}
% Row 7: upregion, downregion, read
\begin{minipage}{\linewidth}
\vspace{-0.2cm}
\begin{tabular}{m{6cm}m{6.5cm}m{6.5cm}}
\infrule[E-UpRgn]{\opsenvx e \mapsto v, E}{\opsenvx \text{upregion}(e, \oton{r}) \mapsto v, E} &
\infrule[E-DownRgn]{\opsenvx e \mapsto l, E \\ v = \begin{cases} l, & \text{if $\exists i, l \in M(r_i)$}. \\ null, & \text{otherwise}. \end{cases}}{\opsenvx \text{downregion}(e, \oton{r}) \mapsto v, E} &
\infrule[E-Read]{\opsenvx e \mapsto l, E \andalso S' = \text{apply}(S, E) \\ v = \begin{cases} S'(l), & \text{if } l \not\in C \\ v' : H(l), & \text{otherwise} \end{cases}}{\opsenvx \text{read}(e) \mapsto v, E \dplus [ read(l, excl, v) ]}
\end{tabular}
\end{minipage}
% Row 8: write, reduce
\begin{minipage}{\linewidth}
\vspace{-0.5cm}
\begin{tabular}{m{9cm}m{9cm}}
\infrule[E-Write]{\opsenvx e_1 \mapsto l, E_1 \andalso S' = \text{apply}(S, E_1) \\
  \opsenvx[S=S'] e_2 \mapsto v, E_2 \andalso valid\_interleave(S, C, E', E_1, E_2)}
  {\opsenvx \text{write}(e_1, e_2) \mapsto l, E' \dplus [ write(l, excl, v) ]} &
\infrule[E-Reduce]{\opsenvx e_1 \mapsto l, E_1 \andalso S' = \text{apply}(S, E_1) \\
  \opsenvx[S=S'] e_2 \mapsto v, E_2 \andalso valid\_interleave(S, C, E', E_1, E_2)}
  {\opsenvx \text{reduce}(id, e_1, e_2) \mapsto l, E' \dplus [ reduce_{id}(l, excl, v) ]}
\end{tabular}
\end{minipage}
% Row 9: pack, unpack
\begin{minipage}{\linewidth}
\vspace{-0.5cm}
\begin{tabular}{m{8cm}m{10cm}}
\infrule[E-Pack]{\opsenvx e_1 \mapsto v, E \andalso \rho_i = M[r_i], \text{ for } 1 \leq i \leq k \\
  v' = \langle \langle \otok{k}{\rho}, v \rangle \rangle}
  {\opsenvx \text{pack}\ e_1\ \text{as}\ T_1[\otok{k}{r}] \mapsto v', E} &
\infrule[E-Unpack]{\opsenvx e_1 \mapsto \langle \langle \otok{k}{\rho} , v_1 \rangle \rangle, E_1 \andalso M' = M[\rho_1/r_1, \ldots, \rho_k/r_k] \\
  L' = L[v_1/id] \andalso S' = \text{apply}(S, E_1) \\
  \opsenvx[M=M',L=L',S=S'] e_2 \mapsto v_2, E_2 \andalso valid\_interleave(S, C, E', E_1, E_2)}
  {\opsenvx \text{unpack}\ e_1\ \text{as}\ id : T_1[\otok{k}{r}] \text{in}\ e_2 \mapsto v_2, E'}
\end{tabular}
\end{minipage}
% Row 10: task call
\begin{minipage}{\linewidth}
%\vspace{-0.5cm}
\infrule[E-Call]{\opsenvx e_1 \mapsto v_1, E_1 \andalso S_1 = \text{apply}(S, E_1) \andalso \opsenvx e_2 \mapsto v_2, E_2 \andalso \ldots \andalso S_n = \text{apply}(S_{n-1}, E_n) \\
  valid\_interleave(S, C, E', \oton{E}) \andalso \text{function }id[\otok{k}{r'}](a_1 : T_1, \ldots, a_n : T_n), \Phi', Q' : T_r = e_{n+1} \\
  M' = \{ (r'_1, M(r_1)), \ldots (r'_k, M(r_k)) \} \andalso L' = \{ (a_1, v_1), \ldots, (a_n, v_n) \} \andalso S' = \text{apply}(S, E') \\
  C' = C \cup \{ l : \exists \rho. atomic(\rho) \in M' \llbracket Q' \rrbracket \vee simult(\rho) \in M' \llbracket Q' \rrbracket \} \\
  \opsenvx[M=M',L=L',S=S',C=C'] e_{n+1} \mapsto v_{n+1}, E_{n+1} \andalso E'_{n+1} = mark\_coherence(E_{n+1}, M' \llbracket Q' \rrbracket) \andalso valid\_interleave(S, C, E'', E', E_{n+1})}
  {\opsenvx id[\otok{k}{r}](\oton{e}) \mapsto v_{n+1}, E''}
\end{minipage}
\end{center}
\end{adjustwidth}
\caption{Legion Core Operational Semantics}
\label{fig:semantics}
\end{figure*}

\section{Soundness of Privileges}
\label{sec:soundness}

A key property of the Legion type system is that any expression that is well-typed is
guaranteed to access the heap only in ways permitted by the privileges under which it was typed.
A judgment $\privconsist{E}{\Phi}$ holds if all the memory operations in memory trace $E$ are of the types and
to locations covered by the privileges in $\Phi$:
\[ 
\begin{array}{l}
\privconsist{E}{\Phi} \Leftrightarrow \forall \epsilon \in E. \\
\quad\quad (\epsilon = read(l, c, v) \Rightarrow \exists r. l \in M(r) \wedge reads(r) \in \Phi)\ \wedge \\
\quad\quad (\epsilon = write(l, c, v) \Rightarrow \exists r. l \in M(r) \wedge writes(r) \in \Phi)\ \wedge \\
\quad\quad (\epsilon = reduce_{id}(l, c, v) \Rightarrow \exists r. l \in M(r) \wedge reduces_{id}(r) \in \Phi)
\end{array}
\]

Our goal is to show $\privconsist{E}{\Phi}$ holds for any execution of an expression $e$ with static privileges $\Phi$.
As usual, even stating such a claim requires that corresponding parts of the initial static and dynamic environments be consistent.
For our results, three consistency properties are needed:
\begin{itemize}
\item mapping consistency, written $\mapconsist{\Omega}$, guarantees a region mapping $M$ satisfies the region constraints $\Omega$ under
which an expression was typed
\item local value consistency, written $\localconsist{L}{\Gamma}$, guarantees local values in $L$ have types consistent with the environment under which the expression was typed
\item store consistency, written $\storeconsist{S}{H}$, guarantees every location in the store $S$ contains a value consistent with the location's type in the heap typing $H$
\end{itemize}

\noindent Two additional properties are proven for each subexpression:
\begin{itemize}
\item result value consistency, written $\valueconsist{v}{T}$, guarantees any evaluation of an expression yields a value of the right type
\item memory trace consistency, written $\traceconsist{E}$, guarantees that all writes and reductions use values of the right types
\end{itemize}
Figure~\ref{fig:constprop} gives the precise definition of these properties.

\begin{figure*}
\centering{\footnotesize
$
\begin{array}{l}
\begin{array}{ll}
\begin{array}{lll}
\mapconsist{\Omega} & \Leftrightarrow & (\forall r_i, r_j. r_i \leq r_j \in \Omega \Rightarrow M(r_i) \subseteq M(r_j))\ \wedge \\
              &                 & (\forall r_i, r_j. r_i * r_j \in \Omega \Rightarrow M(r_i) \cap M(r_j) = \emptyset) \\
\localconsist{L}{\Gamma} & \Leftrightarrow & \forall (id,v) \in L. \valueconsist[]{v}{M \llbracket \Gamma \rrbracket (id)} \\
\storeconsist{S}{H} & \Leftrightarrow & \forall (l,v) \in S. \valueconsist[]{v}{H(l)} \\
\end{array} & 
\begin{array}{lll}
\traceconsist{E} & \Leftrightarrow & (\forall l, c, v. write(l,c, v) \in E \Rightarrow \valueconsist[]{v}{H(l)})\ \wedge \\
& & (\forall id, l, v. reduce_{id}(l, v) \in E \Rightarrow \\
& & (M \llbracket \Gamma \rrbracket (id) = (\hat T_1, \hat T_2), \emptyset, \emptyset \Rightarrow \hat T_1) \wedge H(l) = \hat T_1 \wedge \valueconsist[]{v}{\hat T_2}) \\
\end{array}
\end{array} \vspace{3mm} \\
\begin{array}{l@{\hspace{1cm}}l}
\begin{array}{l}
\valueconsist[]{bv}{bool} \\
\valueconsist[]{iv}{int} \\
\valueconsist[]{null}{\hat T@\rho} \\
\end{array} &
\begin{array}{lll}
\valueconsist[]{l}{\hat T@\rho} & \Leftrightarrow & l \in \rho \wedge H(l) = \hat T \\
\valueconsist[]{\tuple{v_1}{v_2}}{\tuple{\hat T_1}{\hat T_2}} & \Leftrightarrow & (\valueconsist[]{v_1}{\hat T_1}) \wedge (\valueconsist[]{v_2}{\hat T_2}) \\
\valueconsist[]{\langle \langle \oton{\rho}, v \rangle \rangle}{\text{rr}[\oton{r}]\ \hat T\text{ where }\Omega} & \Leftrightarrow & (\valueconsist[]{v}{T[\rho_1/r_1, \ldots \rho_n/r_n]}) \wedge (\mapconsist[\{ (r_i, \rho_i) \}]{\Omega}) \\
\valueconsist[]{K}{coloring(\rho)} & \Leftrightarrow & \forall l_1, v_1. (l_1, v_1) \in K \Rightarrow (l_1 \in \rho\ \wedge \\
& & \forall l_2, v_2. (l_2, v_2) \in K \Rightarrow (l_1 \not= l_2) \vee (v_1 = v_2)) \\
\end{array}
\end{array}
\end{array}
$
}
\caption{Consistency Properties}
\label{fig:constprop}
\vspace{-5mm}
\end{figure*}

\begin{thm}
\label{thm:effects}
\rm
If $\typeenv{e}{T}$ and $\opsenv{e}{v}{E}$  and $\mapconsist{\Omega}$, $\localconsist{L}{\Gamma}$ and $\storeconsist{S}{H}$,
then
$\valueconsist{v}{T}$, $\traceconsist{E}$ and $\privconsist{E}{\Phi}$.
\end{thm}

The proof, which can be found in \cite{LegionTypes12}, is lengthy but
straightforward due to the way in which the operational semantics were
constructed.  It proceeds by standard induction on the structure of the
derivation in the operational semantics, at each step showing that
subexpressions have consistent starting environments and that the
value and trace consistency of the subexpressions is sufficient to prove
the consistency of the parent expression.

\texcomment{
We spare the reader the lengthy proof, which can be found in
\cite{LegionTypes12}, and merely outline the general strategy.  The
proof is a standard induction on the structure of the derivation in
the operational semantics.  The proof is organized into six pieces,
one for each of the three consistency properties that must be shown
for the execution environment of subexpressions and one for each of
the three properties of the execution's results we wish to show:

\texcomment{
For each of 
the 23 different forms a Legion expression can have, we assume the soundness of the subexpressions'
evaluations (provided we can show the consistency of the mappings and store used by that
subexpression) and prove that the result of the expression's evaluation is sound.  Although there
are a multitude of cases to be proven, many of them are similar, and benefit from
the use of the following lemmas:

\begin{lem}
\label{lemma:heapconst:apply}
If $\storeconsist{S}{H}$ and $\traceconsist{E}$, then $\storeconsist{\text{apply}(S, E)}{H}$.
\end{lem}

\begin{lem}
\label{lemma:heapconst:effects1}
If $\traceconsist{E_1}$ and $\traceconsist{E_2}$, then $\traceconsist{E_1 \dplus E_2}$.
\end{lem}

\begin{lem}
\label{lemma:heapconst:effects2}
If $\traceconsist{E_1}$ and $\traceconsist{E_2}$ and $valid\_interleave(S, C, E', E_1, E_2)$, then $\traceconsist{E'}$.
\end{lem}

\begin{lem}
\label{lemma:effsound:effects1}
If $\privconsist{E_1}{\Phi}$ and $\privconsist{E_2}{\Phi}$, then $\privconsist{E_1 \dplus E_2}{\Phi}$.
\end{lem}

\begin{lem}
\label{lemma:effsound:effects2}
If $\privconsist{E_1}{\Phi}$ and $\privconsist{E_2}{\Phi}$ and $valid\_interleave(S, C, E', E_1, E_2)$, then $\privconsist{E'}{\Phi}$.
\end{lem}

\begin{lem}
\label{lemma:omegaclosure}
$\mapconsist{\Omega^*}$ if and only if $\mapconsist{\Omega}$.
\end{lem}

\begin{lem}
\label{lemma:phiclosure}
$\privconsist{E}{\Phi^*}$ if and only if $\privconsist{E}{\Phi}$.
\end{lem}

The proofs of these lemmas can also be found here\cite{LegionTypes12}.  
}

\vspace{4pt}
\hangindent=2\parindent \hangafter=1 \noindent %
$\mapconsist{\Omega}$ - Three expressions have subexpressions that modify $M$ or $\Omega$ and therefore do not
trivially satisfy region mapping consistency.  For {\tt partition},
the consistency of the coloring preserves region mapping consistency
with respect to the constraints.  For {\tt unpack}, the consistency of
a region relation instance guarantees consistency of region mapping.
Finally, the body of a called function uses an initially-empty set of
constraints, which are trivially satisfied.

\vspace{4pt}
\hangindent=2\parindent \hangafter=1 \noindent %
$\localconsist{L}{\Gamma}$ -  Four expressions have subexpressions that modify $L$, $\Gamma$, or $M$.  For
{\tt partition}, which only modifies $M$, the requirement that it not reuse existing
names ensures that $M \llbracket \Gamma \rrbracket$ does not change.  For {\tt let},
the value and type of the binding is obviously consistent, while the binding created in
an {\tt unpack} is less obviously so, requiring an induction over the type of the 
unpacked value to show equivalence under the new mapping.  The last case is the body of a
called function, which requires the same style of proof as for {\tt unpack} 
for each formal parameter.

\vspace{4pt}
\hangindent=2\parindent \hangafter=1 \noindent %
$\storeconsist{S}{H}$ -  The heap typing consistency of all stores used in subexpressions follows directly from the following
lemma: If $\storeconsist{S}{H}$ and $\traceconsist{E}$, then $\storeconsist{\text{apply}(S, E)}{H}$.

\vspace{4pt}
With the necessary consistency conditions proven for a subexpression, the conclusion of the theorem follows for
the subexpression by the inductive hypothesis.  The remaining obligation is to prove the the three parts of the
conclusion for an entire expression:

\vspace{4pt}
\hangindent=2\parindent \hangafter=1 \noindent %
$\valueconsist{v}{T}$ - The consistency of 
{\tt upregion} is guaranteed by the type checking requirement of appropriate subregion
constraints and the mapping's consistency with those constraints, and {\tt downregion}'s
result is consistent because of the run time check.  
%(The requirement
%for appropriate constraints in the {\em downregion} typing rule is primarily for performance
%(i.e. knowing which part of the region tree to examine) and to catch downcasts that will never
%work at runtime.) 
The consistency of a {\tt read}'s result is trivial for an address in the
clobber set and uses the consistency of the store otherwise.  The consistency of a 
{\tt color}'s result depends on the pointer subexpression's consistency and the 
removal of any previous coloring of that location from the coloring set.  

\hangindent=2\parindent \hangafter=1 \indent\indent\indent %
The remaining interesting cases arise from changes to the mapping $M$ rather than transformations on the
value $v$.  In the case of {\tt partition} and {\tt unpack}, the type system
guarantees that the subexpression's result cannot use the regions that were added to the
mapping, allowing the changes to the mapping to be ignored.  The last case is again the body
of a called function, and the same strategy that was used for the type consistency of the
formal parameters works in reverse for the function's result.

\vspace{4pt}
\hangindent=2\parindent \hangafter=1 \noindent %
$\traceconsist{E}$ -  The type consistency of the values in an expression's memory
trace follows from the following lemma applied to the traces of subexpressions:
if $\traceconsist{E_1}$ and $\traceconsist{E_2}$ and $any\_interleave(E', E_1, E_2)$, then $\traceconsist{E'}$.
New memory operations are added by {\tt write} and {\tt reduce} expressions, but consistency follows
directly from the induction hypothesis.  Finally, the consistency of the
values in a called function's memory trace is addressed in the same way as the return value.

\vspace{4pt}
\hangindent=2\parindent \hangafter=1 \noindent %
$\privconsist{E}{\Phi}$ -  The proof of the crucial property of containment of heap accesses within the available privileges
is similar in outline to the previous step.  The easy cases are covered by a lemma combining the corresponding results
for subexpressions: if $\privconsist{E_1}{\Phi}$ and $\privconsist{E_2}{\Phi}$ and $any\_interleave(E', E_1, E_2)$, then $\privconsist{E'}{\Phi}$.
Straightforward proofs cover {\tt read}, {\tt write}, {\tt reduce}, and one final special case for function calls. 
}


\section{Coherence}
\label{sec:coherence}

Theorem~\ref{thm:effects} guarantees that a function call produces a value of the
correct type and does so within the regions of memory for which privileges are held.  In fact, this results holds
even if the {\em valid\_interleave} constraint is weakened to just require an arbitrary interleaving of the memory
traces of subexpressions (i.e. the {\em any\_interleave} predicated defined in Figure~\ref{fig:opsecfns}).  The 
additional constraints on {\em valid\_interleave} in Figure~\ref{fig:validinterleave} address the coherence of 
heap accesses and allow for the per-region relaxation of coherence that is introduced in Legion.

To determine whether an interleaving of two or more memory traces is valid, we consider three sets of addresses:
\begin{itemize}
\item exclusive locations ($l \in L_{excl}$) are those which have at least once access in exclusive mode in the traces
and are not in the clobber set.  For these locations, we require the standard {\em sequential consistency} - all
reads to these locations see the effect of previous writes and reductions, and the resulting state of the store is
as if all writes and reductions were applied from each trace in order
\item atomic locations ($l \in L_{atomic}$) are those which have at least one access in atomic mode in the traces and
are in neither $L_{excl}$ nor the clobber set.  For these locations, we allow permutations of the original
subexpression trace order.
\item for locations that have only access in {\em simult} mode or are in the clobber set, no constraints are
enforced.  The validity of the interleaving of these accesses will be performed in the an enclosing expression.
\end{itemize}

\begin{figure*}
$$
\begin{array}{lll}
valid\_interleave(S, C, E', \oton{E}) & = & any\_interleave(E', \oton{E}) \wedge \\
& & coherent(S, L_{excl}(E', C), L_{excl}(E', C), E')\ \wedge \\
& & seq\_equiv(S, L_{excl}(E', C), L_{excl}(E', C), E', \oton{E})\ \wedge \\
& & coherent(S, L_{atomic}(E', C), \emptyset, E')\ \wedge \\
& & \exists \oton{\pi}, (\oton{\pi}) \text{ is a permutation of } (1,\ldots,n)\ \wedge \\
& & \ \ \ seq\_equiv(S, L_{atomic}(E', C), \emptyset, E', E_{\pi_1}, \ldots, E_{\pi_n}) \\
coherent(S, L_1, L_2, []) & = & \text{true} \\
coherent(S, L_1, L_2, [ \epsilon ] \dplus E) & = &\
\begin{cases}
(l \in L_2 \Rightarrow S(l) = v)\ \wedge \\
\ \ \ coherent(S, L_1, L_2, E), & \text{if $\epsilon = read(l, c, v)$} \\
coherent(apply(S, \epsilon), L_1, L_2 \cup \{ l \}, E), & \text{if $\epsilon = write(l, c, v)$ and $l \in L_1$} \\
coherent(apply(S, \epsilon), L_1, L_2, E), & \text{otherwise}
\end{cases} \\
seq\_equiv(S, L_1, L_2, E', \oton{E}) & = & coherent(S, L_1, L_2, E_1 \dplus \ldots \dplus E_2)\ \wedge \\
& & \forall l \in L_1. apply(S, E')(l) = apply(S, E_1 \dplus \ldots \dplus E_n)(l) \\
L_{excl}(E, C) & = & \{ l : op(l, excl, v) \text{ in } E  \} \setminus C \\
L_{atomic}(E, C) & = & \{ l : op(l, atomic, v) \text{ in } E \} \setminus (C \cup L_{excl}(E, C)) \\
\end{array}
$$
\caption{Valid Interleaving Test}
\label{fig:validinterleave}
\vspace{-5mm}
\end{figure*}

Although it is our goal to enable parallel execution whenever possible, it will help to briefly
consider serialized execution of a Legion program.  We will show that a serial execution trivially
satisfies the interleaving criteria required by the Legion operational semantics.  In addition to
serial execution being the fallback behavior of the hierarchical schedule, our proof of the
soundness of the parallel scheduling will depend on this result.

Serial execution is achieved by ignoring the coherence mode $Q$ in all function calls, using $Q' = \emptyset$
instead, and by forming ``interleaved'' traces by simply concatenating the subexpressions' traces.  By ignoring
the coherence modes, the clobber set remains empty, making the result of all {\em read} expressions fully
determined.  The following lemma and theorem (proofs of which can be found in \cite{LegionTypes12}) show that the
value and memory trace that result from a serialized execution of an expression are always valid executions of
Legion programs.

\begin{lem}
\label{lem:clobberreduce}
\rm 
Let $\typeenv{e}{T}$ and $\opsenv{e}{v}{E}$ and $\storeconsist{S}{H}$.  If $C \subseteq C'$, then
$\opsenv[C=C']{e}{v}{E}$.
\end{lem}

\begin{thm}
\label{thm:sequential}
\rm
Let $\oton{e}$ be expressions such that 
%$\opsenv[S={S_{i-1}}]{e_i}{v_i}{E_i}$, 
$M, L, H, S_{i-1},\linebreak C \vdash e_i \mapsto v_i, E_i$,
where $S_i = apply(S_{i-1}, E_i)$.  If $E' = E_1 \dplus \ldots \dplus E_n$, then
$valid\_interleave(S_0, C, E', \oton{E})$.
\end{thm}

CURRENT EDIT POINT

Next we examine how to modify the serialized interleaving to produce valid interleavings allowing parallel execution. 
We consider when we may swap the order of two adjacent memory operations in a valid interleaving.
\begin{itemize}
\item The two operations must have come from different constituent
traces, or the swap would violate $any\_interleave$.
\item If one is a read of
a location $l$ (that is not in the clobber set), the other may not be a write or reduce to $l$, 
as changing the order would almost certainly change the value read.
\item If one is a write of a location $l$, the other may not be a write or reduce to $l$,
as the store that would result from applying those operations in the opposite order may
differ in $l$.
\item Finally, if both operations are reductions to the same location, they may be swapped if they
use the same reduction function, as each reduction function is assumed to commute with itself.  
%(We 
%follow the example of other work (i.e. DPJ) and leave proofs of commutativity to the programmer,
%possibly with the aid of other tools.)  
However, if the reduction functions have different names, swapping the two operations might result in a different store.
\end{itemize}

To summarize this, we define a {\em non-interference} operator on two memory operations that have been
annotated with which constituent trace they came from as follows:
$$
\begin{array}{l@{ }l}
op_1^{E_1}(l_1, c_1,& v_1)\ \nonint\ op_2^{E_2}(l_2, c_2, v_2) \Leftrightarrow E_1 \not= E_2\ \wedge \\
& \big( l_1 \not= l_2 \vee (op_1 = read \wedge op_2 = read)\ \vee \\
& (op_1 = reduce_{id_1} \wedge op_2 = reduce_{id_2} \wedge id_1 = id_2) \big)
\end{array}
$$

\begin{lem}
\label{lem:nonintswap}
\rm
Let $S$ be a store, $C$ a clobber set, $\oton{E}, E'_a, E'_b$ memory traces, and
$\epsilon_1, \epsilon_2$ two annotated memory operations such that $\epsilon_1 \nonint \epsilon_2$.
Then,
$$valid\_interleave(S, C, E'_a \dplus [ \epsilon_1, \epsilon_2 ] \dplus E'_b, \oton{E})$$
if and only if
$$valid\_interleave(S, C, E'_a \dplus [ \epsilon_2, \epsilon_1 ] \dplus E'_b, \oton{E}).$$
\end{lem}
\texcomment{
\begin{proof}
As before, we consider the three conditions needed to be a valid interleaving.  We describe the
implication in the ``forward'' direction, but the arguments are all symmetric.
\begin{enumerate}
\item If $E'_a \dplus [ \epsilon_1 ] \dplus [ \epsilon_2 ] \dplus E'_b$ is an interleaving of $\oton{E}$,
the proof must first ``pop off'' all of $E'_a$, leaving $[ \epsilon_1 ] \dplus [ \epsilon_2 ] \dplus E'_b$ for
the interleaved subtrace.  The next two steps must pop $\epsilon_1$ and $\epsilon_2$, leaving $E'_b$.
They cannot be in the same subtrace because $\epsilon_1 \nonint \epsilon_2$, so we could also pop
$\epsilon_2$ and then $\epsilon_1$, resulting in a proof that $E'_a \dplus [ \epsilon_2 ] \dplus [ \epsilon_1 ] \dplus E'_b$ is also an interleaving of the constituent traces.
\item For coherence, we must show the value read (if any) by $\epsilon_1$ does not change, the value
read (if any) by $\epsilon_2$ does not change, and that any read in $E'_b$ sees no change.  With the
help of Lemma~\ref{lemma:applychain}, we can eliminate the common $E'_a$ from all sequences by
using $S' = apply(S, E'_a)$.  Similarly to show that $apply(S', [ \epsilon_1  ] \dplus [ \epsilon_2 ] \dplus E) = apply(S', [ \epsilon_2 ] \dplus [ \epsilon_1 ] \dplus E)$ for any $E$, we need only to show that it holds
for $E = []$.  The proof is now reduced to showing the following:
\begin{enumerate}
\item $\epsilon_1 = read(l, c, v) \Rightarrow S'(l) = apply(S',\epsilon_2)(l)$ - since $\epsilon_1$
is a read, either $\epsilon_2$ must be a read (in which case $apply(S, \epsilon_2) = S'$) or must be
to a different location, so the result of applying just it to $S'$ cannot change the value in 
location $l$.
\item $\epsilon_2 = read(l, c, v) \Rightarrow apply(S', \epsilon_1)(l) = S'(l)$ - this is the same
as above, with $\epsilon_1$ and $\epsilon_2$ switched.
\item $apply(S', \epsilon_1 \dplus \epsilon_2) = apply(S', \epsilon_2 \dplus \epsilon_1)$ - we must
show that the two store operations $apply(\bullet, \epsilon_1)$ and $apply(\bullet, \epsilon_2)$
commute.  Modifications to two different locations commute, as do two reads (which make no change
to the store).  Finally, two reductions using the same function to the same location also commute.
\end{enumerate}
\item The proof that sequential equivalence is maintained comes down to showing the final store
is identical after the swap of the two operations, and this is merely a special case of the third
piece of the coherence proof.
\end{enumerate}
\end{proof}
}
We now extend the non-interference operator to entire memory traces, providing a way to say that
no operation in a trace interferes with any operation in another:
$$E_1 \nonint E_2 \Leftrightarrow \displaystyle\bigwedge_{\epsilon_1 \text{ in } E_1, \epsilon_2 \text{ in } E_2} \epsilon_1 \nonint \epsilon_2$$
and observe that this property permits arbitrary ordering (i.e. parallel execution) of the 
corresponding subexpressions.

\begin{lem}
\label{lem:noninteffects}
\rm
Let $S$ be an initial store, $C$ be a clobber set, $\oton{E}$ be memory traces such that $E_i \nonint E_j$
for every $1 \leq i < j \leq n$.  Then any trace $E'$ satisfying $any\_interleave(E', \oton{E})$
is a valid interleaving.
\end{lem}
\texcomment{
\begin{proof}
We will use Theorem~\ref{thm:sequential} and Lemma~\ref{lem:nonintswap} to make repeated swaps
of adjacent operations to transform $E'$ into $E_1 \dplus \ldots \dplus E_n$.  The symmetry of
Lemma~\ref{lem:nonintswap} is then used to show that the validity of $E_1 \dplus \ldots \dplus E_n$
under Theorem~\ref{thm:sequential} implies the validity of $E'$.

The swapping algorithm as follows: Associate with each operation in $E'$ the index of that operation
in $E_1 \dplus \ldots \dplus E_n$.  Any consecutive pair of operations $\epsilon_1$ and $\epsilon_2$
for which $index(\epsilon_1) > index(\epsilon_2)$ is a {\em misordered pair}.  For any such pair,
$\epsilon_1$ and $\epsilon_2$ will be from different constituent traces (if they were from the same
trace, their misordering would mean that $E'$ was not an interleaving of $\oton{E}$).  Every pair of
traces is non-interfering, so $\epsilon_1 \nonint \epsilon_2$ and they can be swapped while preserving
validity of the trace.  At most $n^2/2$ swaps are needed to eliminate all misordered pairs.
\end{proof}
}
We next extend non-interference to privileges.  We 
use the region mapping $M$ to translate the logical regions named in privileges into sets of
locations (i.e. physical regions), and define non-interference between individual privileges and
sets of privileges:
$$
\begin{array}{@{}l@{}}
priv_1(r_1) \nonint[M] priv_2(r_2) \Leftrightarrow (M(r_1) \cap M(r_2) = \emptyset)\ \vee \\
\hspace{0.35in} (priv_1 = reads \wedge priv_2 = reads)\ \vee \\
\hspace{0.35in} (priv_1 = reduces_{id_1} \wedge priv_2 = reduces_{id_2} \wedge id_1 = id_2)
\end{array}
$$
%% \begin{center}
%% \begin{tabular}{llc}
%% \multicolumn{1}{c}{$\phi_1$} & \multicolumn{1}{c}{$\phi_2$} & $\phi_1 \nonint[M] \phi_2$? \\
%% \multirow{3}{*}{$reads(r_1)$} & $reads(r_2)$ & true \\
%% & $writes(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $reduces_{id_2}(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% \cline{1-1}
%% \multirow{3}{*}{$writes(r_1)$} & $reads(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $writes(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $reduces_{id_2}(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% \cline{1-1}
%% \multirow{3}{*}{$reduces_{id_1}(r_1)$} & $reads(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $writes(r_2)$ & $M(r_1) \cap M(r_2) = \emptyset$ \\
%% & $reduces_{id_2}(r_2)$ & $\begin{array}{c}id_1 = id_2 \vee \\ M(r_1) \cap M(r_2) = \emptyset\end{array}$ \\
%% \end{tabular}
%% \end{center}

$$\Phi_1 \nonint[M] \Phi_2 \Leftrightarrow \displaystyle\bigwedge_{\phi_1 \in \Phi_1, \phi_2 \in \Phi_2} \phi_1 \nonint[M] \phi_2$$

\begin{lem}
\label{lem:nonintpriv}
\rm
Let $M$ be a region mapping and $E_1$ and $E_2$ two memory traces such that $\privconsist{E_1}{\Phi_1}$ and $\privconsist{E_2}{\Phi_2}$.  If $\Phi_1$ and $\Phi_2$ are non-interfering under $M$, then $E_1$ and $E_2$ must be non-interfering.
\end{lem}
\texcomment{
\begin{proof}
The proof is by contradiction.  Assume $E_1 \cancel\nonint E_2$.  Then there must be some $\epsilon_1$ in $E_1$ and some $\epsilon_2$ in $E_2$ such that $\epsilon_1 \cancel\nonint \epsilon_2$.  This requires that
$\epsilon_1$ and $\epsilon_2$ be operations to the same location $l$ and not both be reads or both
reductions using the same function name.  Assume $\epsilon_1 = read(l, c_1, v_1)$ and $\epsilon_2 = write(l, c_2, v_2)$.  The definition of $\privconsist{E_1}{\Phi_1}$ tells us that there must be some $r_1$ satisfying $l \in M(r_1) \wedge reads(r_1) \in \Phi_1$.  Similarly, there must be some $r_2$ satisfying $l \in M(r_2) \wedge writes(r_2) \in \Phi_2$.  Letting $\phi_1 = reads(r_1)$ and $\phi_2 = writes(r_2)$, we have $M(r_1) \cap M(r_2) \not= \emptyset$ (it contains at least $l$), so $\phi_1 \cancel{\nonint[M]} \phi_2$ and $\Phi_1 \cancel{\nonint[M]} \Phi_2$.  There are seven other cases to consider (using $id_1 \not= id_2$ for the reduce-reduce case), but all yield the same result.
\end{proof}
}
We can now state the key result that allows the Legion runtime to safely evaluate subexpressions as
separate tasks in parallel.

\begin{thm}
\label{thm:parallelexec}
\rm
Let $\oton{e}$ be well-typed Legion expressions, each with its own privileges $\Phi_i$.
Let $M$ be a region mapping, $L$ a local value mapping,
$H$ a heap typing, and $S$ be an initial store satisfying
$\mapconsist{\Omega}$, $\localconsist{L}{\Gamma}$, and $\storeconsist{S}{H}$.
If $\Phi_i \nonint[M] \Phi_j$ for $1 \leq i < j \leq n$, then any parallel execution of expressions
$\oton{e}$ results in a valid interleaving of memory operations.
\end{thm}

The proof follows directly from Lemmas~\ref{lem:noninteffects}
and \ref{lem:nonintpriv}.  This result holds even if the
clobber set $C$ is non-empty, allowing two ``locally independent''
subtasks to run in parallel even if one or both of them is interacting
(in a programmer-permitted way) with a third subtask.

We now highlight an important aspect of the Legion
implementation that is different from other systems and relies on the
soundness of privileges.  Non-interference of memory operations is
something that can only be determined after evaluation of an
expression is completed, and only at great expense, as illustrated at
one extreme by work on transactional
memory \cite{Harris05}.  At the other extreme are systems
that check non-interference statically, such as Jade \cite{Rinard98} and
DPJ \cite{Bocchino11}.  In contrast, Legion checks non-interference of privileges
at runtime, which is much simpler and more efficient than checking
non-interference of dynamic memory traces.  Even though the privileges
themselves are static, the region mapping $M$ is dynamic.  Testing
non-interference on the privileges with physical regions allows
parallel execution in many more cases than a purely static analysis
can achieve.



\subsection{Relaxed Coherence}
\label{subsec:relaxed}

The analysis above does not consider the coherence modes of operations,
making the worst-case assumption that all operations use $excl$ mode.  However, if two or more
subexpressions contain calls to functions using $atomic$ or $simult$ coherence modes
on some regions, executions besides serial program order may 
result in valid interleavings even if constituent traces have locations in common.  We discuss
two cases of interest.  In both, the previous section's analysis 
is repeated with minor modifications, so for brevity we limit
discussion to a description of the differences rather than complete proofs.

The first important case occurs when all apparently-interfering operations have coherence modes
of either $atomic$ or $simult$.  In this case, the conditions required for
coherence and sequential equivalence are trivially satisfied for locations in $L_{excl}$.  The
requirements for locations in $L_{atomic}$ allow any permutation of the constituent traces,
so the runtime is free to serialize the execution of the subexpressions in any order, not just
program order.

To convert the required analysis to one that can be performed on regions, we modify
the non-interference operator for memory operations to consider only locations in $L_{excl}$ and show that
traces that are non-interfering under this modified check satisfy the requirement for atomic
execution.  We then modify the non-interference operator on privileges to allow 
$M(r_1) \cap M(r_2) \not= \emptyset$ if either $atomic(r_1)$ or $simult(r_1)$ is in $Q_1$ and
either $atomic(r_2)$ or $simult(r_2)$ is in $Q_2$. We then show that subexpressions with 
privileges that are {\em atomically non-interfering} (under a dynamic region mapping
$M$) always have memory traces compatible with atomically-reordered execution.  Finally,
in the special case where each subexpression has $atomic(r)$ or $simult(r)$ in $Q_i$ for every $r$
in $\Phi_i$, we can eliminate the dynamic check entirely.

The second case is a subset of the first, in which all apparently-interfering operations have
the $simult$ coherence mode.  In this case, all the coherence and sequential equivalence 
checks are trivially satisfied, and any interleaving of the constituent traces is valid.
We again modify the non-interference criteria for memory operations, traces, and privileges, this time
only allowing $simult$ coherence annotations. We show that subexpression with privileges
that are {\em simultaneously non-interfering} (under mapping $M$) can be executed
in parallel, which includes all the cases covered by Theorem~\ref{thm:parallelexec} as well
as those where the programmer has used the $simult$ coherence mode to explicitly allow parallel
execution.  Again, a special (but important) case exists where all privileges for each
subexpression are paired with $simult$ coherence mode declarations, allowing the safety of
parallel execution to be determined at compile time.

\section{Hierarchical Scheduling}
\label{sec:scheduling}

The enforcement of a (locally) valid interleaving at every step in the operational semantics
captures the hierarchical nature of the scheduler used by the Legion runtime.  As the cost of
a scheduling decision is quadratic in the number of function calls (more precisely, the number of 
privileges for those calls), it should be clear that a hierarchical scheduling algorithm will
be vastly more efficient than a global algorithm that must consider the privileges of every
concurrently executing expression.
However, a scheduling algorithm that makes decisions hierarchically must do so with limited
information, and must respect all required scheduling dependencies while ideally imposing as
few extra dependencies as possible.  The following theorem forms the basis of the 
Legion scheduler.

\texcomment{
Let $e_1$ and $e_2$ be well-typed Legion expressions using privileges $\Phi_1$ and
$\Phi_2$.  Now let $e_3$ be some subexpression of $e_1$ and $e_4$ be some 
subexpression of $e_2$, with corresponding privileges $\Phi_3$ and $\Phi_4$.
By Theorem~\ref{thm:parallelexec}, if the runtime can verify $\Phi_1 \nonint[M] \Phi_2$, then 
expressions $e_1$ and $e_2$ may be evaluated in parallel.  The evaluation of the subexpressions
$e_3$ and $e_4$ will therefore be allowed to run in parallel, and we must show that this is
permissible.  We do so by proving that any memory traces that can result from the evaluation
of the subexpression must be non-interfering (allowing parallel execution by
Lemma~\ref{lem:noninteffects}).
}
\begin{thm}
\label{thm:hiersched}
\rm
Let $e_1$ and $e_2$ be well-typed Legion expressions using privileges $\Phi_1$ and
$\Phi_2$ respectively, where $\Phi_1 \nonint[M] \Phi_2$.  Let $e_3$ be a subexpression of $e_1$ and $e_4$ be a 
subexpression of $e_2$.  Any memory traces $E_3$ of $e_3$ and $E_4$ of $e_4$ resulting from evaluation of
$e_1$ and $e_2$ (with the usual consistent $M$, $L$, $H$, and $S$), must be
non-interfering.
\end{thm}
\texcomment{
\begin{proof}
Let $E_1$ be the result of an evaluation of $e_1$, with $E_3$ being the memory trace from the
evaluation of $e_3$ within the expression tree.  $E_1$ will be formed from a tree of valid
interleavings, each of which must include all the memory operations of each constituent trace.
By induction over the number of intermediate subexpressions between $e_1$ and $e_3$, we
can show that any memory operation $\epsilon_3$ that is in $E_3$ must also be in $E_1$.
Similarly, any memory operation $\epsilon_4$ that is in $E_4$ must also be in $E_2$.  We have
$E_1 \nonint E_2$ from Lemma~\ref{lem:nonintpriv}, so and therefore $\epsilon_3 \nonint \epsilon_4$.  Since
this holds for all $\epsilon_3$ in $E_3$ and all $\epsilon_4$ in $E_4$, we have $E_3 \nonint E_4$.
\end{proof}
} The Legion task scheduler uses Theorem~\ref{thm:hiersched} in the
following way.  Sibling function calls (those invoked within the same
function body) are checked for non-interference of their (dynamic)
privileges.  If they interfere they are serialized; otherwise they are
considered for execution as parallel subtasks.  Although determining that $e_1$
and $e_2$ are non-interfering guarantees $e_3$ and $e_4$ are
non-interfering, the converse is not true.  It is possible for $e_1$
and $e_2$ to be judged to be potentially interfering and be serialized
even when the subexpressions are non-interfering.  This loss of
precision can impact performance, and did in a few instances in our
experiments.  
%When the performance impact is significant, two options
%exist to improve matters.  
In cases where $e_1$ and $e_2$ are in fact
non-interfering, region partitions can be further refined to make the
disjointness visible in the privileges.  Alternately, the code can be
refactored to lift the subexpressions up to the same level, allowing
the dynamic test based on the region mapping to infer non-interference
in more cases.  
%Although this can increase the overhead of scheduling
%decisions, judicious use of this technique in practice has not shown
%any measurable performance degradation.

