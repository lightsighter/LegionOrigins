\section{The Software Out-of-Order Processor}
\label{sec:soop}

There are two major challenges in implementing an efficient task
scheduler for Legion:
\begin{itemize}
\item  For correctness, Legion must guarantee that every pair of {\em dependent} tasks is serialized in program order.

\item For performance, Legion must hide the extremely long latencies associated
  with machines that have both distributed memory and many levels of
  memory hierarchy.
\end{itemize}
Our scheduler uses three techniques to achieve both correctness and high performance:
\begin{itemize}
\item If it were necessary to compare all pairs of tasks for dependences that alone
would be a serial bottleneck in all but the simplest Legion programs.  Fortunately,
subtasks enjoy an isolation property that allows Legion to check only task siblings for dependences
(see Section~\ref{sec:dep}).

\item Legion uses a {\em  software out-of-order processor}, or SOOP, to schedule tasks.  The SOOP 
is pipelined and distributed, and also extracts nested parallelism from subtasks.

\item Legion uses a {\em deferred execution model} that decouples the issuing
of operations from when operations are performed.  An issued operation waits for other operations on
which it is dependent to complete before executing, but a waiting operation does not cause the SOOP
to block, allowing Legion to perform other useful work while the operation is pending.  

%  For example, Legion may issue a copy
%operation to move the results of a task $a$ to the place where a task $b$ will take the copied data as
%an argument.  Tasks $a$ and $b$ and the copy can all be issued, but the copy will not start until
%task $a$ completes and task $b$ will not start until the copy completes.

\end{itemize}

Each processor in the machine runs an instance of the SOOP, which handles all requests
for Legion services from tasks executing on the processor.  The SOOP is analagous to the out-of-order
instruction scheduler in superscalar processors, but working at the granularity of tasks and their region
arguments instead of instructions and their register arguments.
Legion's SOOP has a five stage pipeline: dependence analysis (Section~\ref{sec:dep}),
distribution (Section~\ref{sec:dist}),
mapping (Section~\ref{sec:map}),
execution (Section~\ref{sec:exec}),
and clean-up (Section~\ref{sec:clean}).
We discuss each in turn.

\input{mapping_fig}

\subsection{Depedence Analysis}
\label{sec:dep}


When a Legion task runs, it may spawn new subtasks to be executed.  We refer to the
subtasks as {\em children} of the {\em parent} task.  The children of a parent task
are {\em siblings} of each other.

When a parent task spawns a child task, the child is {\em registered} with the SOOP 
on which the parent is executing; registration records the subtask's logical region
arguments and associated privileges and coherence properties.
Children are registered in the sequential execution order in which the parent task
spawns them.

If two children have a dependence between their region arguments, the
SOOP will schedule them to run serially to preserve the program's
sequential semantics.  If two child tasks have no dependence then
Legion can schedule them to execute out of order, in parallel.  Thus,
the first stage in the execution of a task is dependence analysis
between tasks.

\subsubsection{Dependences}
Detecting dependences between a newly registered task $t$ and a previous task 
$t'$ requires comparing the two sets of logical regions accessed.  For each logical region used by
$t'$ that may overlap with a logical region used by $t$, the privileges
and coherence modes are compared to determine whether a dependence exists.  If
both regions need only read privileges there is never a dependence, but if either
task needs write or reduction privileges, the coherence modes are compared using
the table in Figure~\ref{fig:dependence}.

\begin{figure}
{\small
\begin{tabular}{c|cccc}
             & Exclusive & Atomic   & Simultaneous & Relaxed \\
\midrule
Exclusive    & Dep & Dep & Dep & Dep \\ 
Atomic       & Dep & Same & Cont & Cont \\
Simultaneous & Dep & Cont & Same & None \\
Relaxed      & Dep & Cont & None & None \\
\end{tabular}
}
\caption{Dependence table.}
\label{fig:dependence}
\end{figure}
A {\tt Dep} entry indicates dependence while {\tt None}
indicates independence.  A {\tt Same} entry is a dependence unless the two tasks
use the same physical instance of the logical region.\footnote{For example, if two tasks wish to acess the region with atomic coherence, then if they are working on the same physical copy of the data atomicity can be guaranteed using, e.g., locking.  If they are working on different copies of the data then the only safe execution strategy for Legion is to serialize the two tasks.}
A {\tt Cont} entry
indicates a dependence unless a single writer is using the
atomic coherence mode.  When a dependence is detected, the new task
waits for the older task to complete before it begins execution.

The table lists {\em simultaneous} and {\em relaxed} coherence modes
that we have not yet discussed.  Both simultaneous and relaxed
allow other tasks using the region to execute at the same time and differ
only in what data must be observed.  With simultaneous coherence, a task must 
see all updates to the logical region made by other tasks operating on the same region 
simultaneously (i.e., shared memory semantics).  With relaxed coherence, 
a task may or may not observe updates to the logical region by other tasks executing at
the same time.


\subsubsection{Isolation}

\begin{figure}
\centering
\begin{tikzpicture}
\node(top) at (3.5,3.5) { $p$ };

\node(s1) at (1.9,2.5) { $s1$ };
\node(s2) at (5.1,2.5) { $s2$ };

\node(m1) at (1.9,1.5) { $\ldots$ };
\node(m2) at (5.1,1.5) { $\ldots$ };
\node(t1) at (1.9,0.5) { $t_1$ };
\node(t2) at (5.1,0.5) { $t_2$ };

\draw
  (top.south) edge (s1.north)
  (s2.north) edge (top.south)
  (m1.north) edge (s1.south)
  (m2.north) edge (s2.south)
  (t1.north) edge (m1.south)
  (t2.north) edge (m2.south)
  ;

\draw[dashed]
  (t1.east) edge (t2.west)
  (s1.east) edge (s2.west)
  ;

\end{tikzpicture}
\caption{Dependence between tasks implies a dependence between siblings of the least common ancestor.}
\label{fig:independence}
\end{figure}

The reader may wonder why we only compare sibling tasks for
dependences: can't arbitrary pairs of tasks have dependences?  The
answer is ``yes'', but the following lemma shows that
any non-sibling tasks are always detected first as a dependence between
siblings that are registered earlier in execution.
\begin{lemma}
\label{lem:isolation}
\rm
Let $t_1$ and $t_2$ be two distinct, non-sibling tasks other than the root task, let $p$ be the least
common ancestor task of $t_1$ and $t_2$, and let $s_1$ and $s_2$ be the sibling children of $p$ 
that are ancestors of $t_1$ and $t_2$, respectively.
If $t_1$ and $t_2$ have a dependence, then $s_1$ and $s_2$ have a dependence.
\end{lemma}
\begin{proof}
Recall from Section~\ref{sec:ex} that a task's parent, takes region arguments that include the children's region arguments and have only more permissions.  The same is true of any ancestor of a task.
\end{proof}
Lemma~\ref{lem:isolation} is illustrated in Figure~\ref{fig:isolation}:
if arbitrary tasks $t_1$ and $t_2$ have a dependence, then, because tasks always work on a subset
of the data passed to their parents, two siblings $s_1$ and $s_2$ of the task's
least common ancestor also have a dependence.  Since $s_1$ and $s_2$ are issued earlier in the program
execution than $t_1$ and $t_2$, $s_1$ and $s_2$ are serialized by the SOOP and the dependence between
$t_1$ and $t_2$ is observed.   Note that Lemma~\ref{lem:isolation} also guarantees a dual independence property: if two sibling tasks $s_1$ and $s_2$ have no dependence, then there can never be a dependence between the descendants of $s_1$ and the descendants of $s_2$.

\subsubsection{Efficient Dependence Analysis}





To detect dependencies efficiently, the high-level runtime maintains a
local region forest (recall Section~\ref{sec:exec}) for each task.  The
root regions are the task's region arguments, and the forest includes
all partitions and subregions created within the task.  To perform
dependence detection on a region $r$, the runtime first finds a root
region $r'$ such that $r \rleq r'$.  The runtime then walks the region
forest from $r'$ to $r$.  Each region $r''$ on the path contains a
list $L$ of registered tasks using $r''$, and potential dependencies
are discovered by comparing privileges and coherence modes with the
tasks in $L$.

The runtime next checks if a partition of $r''$ is {\em open}.  An
open partition indicates that there are active tasks using subregions
of $r''$.  No more than one partition of a node can be open
at any time.  If the open partition is is along the path to $r$,
traversal continues.  If the open partition lies along another
path the runtime must {\em close} the currently active partition because it cannot guarantee
disjointness with the region the new task wishes to access.  To close a
partition, the runtime finds all active tasks in that
subtree and considers them all dependencies for the new task.
With the previously active partition closed, the runtime can
then open the desired partition and traverse further down the tree as
needed.

When the runtime traverses an open partition, its behavior depends on the kind
of partition being traversed.  If the partition is disjoint, no other subregion
can overlap with the target region, so the state of other subregions is
ignored.  However, if the partition is not disjoint, any
of subregion could overlap with the desired subregion, so
the runtime must close all open subregions (recording new dependencies
as it does so) before continuing the traversal.

After the runtime reaches the target logical region, it performs dependence
checks against any active tasks listed for that region.  If a dependence is
discovered, it is added to the current task's dependence list.  It can then
be removed from the region tree's active task list, as the current task (which
will be pushed onto the active task list) {\em dominates} the previous task.
In a case where the new task has dependencies with all existing active tasks
for the target node, that whole list is replaced by a single entry for the
new task.


\subsection{Distribution}
\label{sec:dist}

\subsection{Mapping}
\label{sec:map}

\subsection{Execution}
\label{sec:exec}

\begin{figure}
\includegraphics[scale=0.48]{figs/CircuitMem.pdf}
\caption{Tasks and data for the circuit simulation on a cluster of GPUs.}
\end{figure}

\subsection{Clean-Up}
\label{sec:clean}

