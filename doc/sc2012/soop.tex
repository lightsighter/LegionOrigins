\section{The Software Out-of-Order Processor}
\label{sec:soop}

There are two major challenges in implementing an efficient task
scheduler for Legion:
\begin{itemize}
\item  For correctness, Legion must guarantee that every pair of {\em dependent} tasks is serialized in program order.

\item For performance, Legion must hide the extremely long latencies associated
  with machines that have both distributed memory and many levels of
  memory hierarchy.
\end{itemize}
Our scheduler uses three techniques to achieve both correctness and high performance:
\begin{itemize}
\item If it were necessary to compare all pairs of tasks for dependences that 
would be a bottleneck in most Legion programs.  Fortunately,
subtasks enjoy an isolation property that allows Legion to check only task siblings for dependences
(see Section~\ref{sec:dep}).

\item Legion uses a {\em  software out-of-order processor}, or SOOP, to schedule tasks.  The SOOP 
is pipelined and distributed, and also extracts nested parallelism from subtasks.

\item Legion uses a {\em deferred execution model} that decouples the issuing
of operations from when operations are performed.  An issued operation waits for other operations on
which it is dependent to complete before executing, but a waiting operation does not cause the SOOP
to block, allowing Legion to perform other useful work while the operation is pending.  

%  For example, Legion may issue a copy
%operation to move the results of a task $a$ to the place where a task $b$ will take the copied data as
%an argument.  Tasks $a$ and $b$ and the copy can all be issued, but the copy will not start until
%task $a$ completes and task $b$ will not start until the copy completes.

\end{itemize}

Each processor in the machine runs an instance of the SOOP, which handles all requests
for Legion services from tasks executing on the processor.  The SOOP is analagous to the out-of-order
instruction scheduler in superscalar processors, but working at the granularity of tasks and their region
arguments instead of instructions and their register arguments.
Legion's SOOP has a five stage pipeline: dependence analysis (Section~\ref{sec:dep}),
distribution (Section~\ref{sec:dist}),
mapping (Section~\ref{sec:map}),
execution (Section~\ref{sec:exec}),
and clean-up (Section~\ref{sec:clean}).
We discuss each stage in turn.

\input{mapping_fig}

\subsection{Depedence Analysis}
\label{sec:dep}


When a Legion task runs, it may spawn new subtasks to be executed.  We refer to the
subtasks as {\em children} of the {\em parent} task.  The children of a parent task
are {\em siblings} of each other.  A task always executes on a single processor, but
its subtasks may execute elsewhere.

When a parent task spawns a child task, the child is {\em registered}
with the SOOP on the processor where the parent is executing;
registration records the subtask's logical region arguments and
associated privileges and coherence properties.  Children are
registered in the sequential execution order in which the parent task
spawns them and enqueued for dependence analysis.  For example, in the
circuit simulation in Listing~\ref{lst:code_ex}, the three spawn
statements on lines 32-34 register will register all of the three
kinds of subtasks (in program order) on the processor where {\tt
simulate\_circuit} executes.

If two children have a dependence between their region arguments, the
SOOP will schedule them to run serially to preserve the program's
sequential semantics.  If two child tasks have no dependence then
Legion can schedule them to execute out of order, in parallel.  Thus,
the first stage in the execution of a task is dependence analysis on
the logical regins used by tasks.

\subsubsection{Dependences}
Detecting dependences between a newly registered task $t$ and a previously registered task 
$t'$ requires comparing the two sets of logical regions accessed.  For each logical region used by
$t'$ that may overlap with a logical region used by $t$, the privileges
and coherence modes are compared to determine whether a dependence exists.  If
both regions need only read privileges there is never a dependence, but if either
task needs write or reduction privileges, the coherence modes are compared using
the table in Figure~\ref{fig:dependence}.

\begin{figure}
{\small
\begin{tabular}{c|cccc}
             & Exclusive & Atomic   & Simultaneous & Relaxed \\
\midrule
Exclusive    & Dep & Dep & Dep & Dep \\ 
Atomic       & Dep & Same & Cont & Cont \\
Simultaneous & Dep & Cont & Same & None \\
Relaxed      & Dep & Cont & None & None \\
\end{tabular}
}
\caption{Dependence table.}
\label{fig:dependence}
\end{figure}
A {\tt Dep} entry indicates dependence while {\tt None}
indicates independence.  A {\tt Same} entry is a dependence unless the two tasks
use the same physical instance of the logical region.\footnote{For example, if two tasks wish to acess the region with atomic coherence, then if they are working on the same physical copy of the data atomicity can be guaranteed using, e.g., locking.  If they are working on different copies of the data then the only safe execution strategy for Legion is to serialize the two tasks.}
A {\tt Cont} entry
indicates a dependence unless a single writer is using the
atomic coherence mode.  When a dependence is detected, the new task
waits for the older task to complete before it begins execution.

The table lists {\em simultaneous} and {\em relaxed} coherence modes
that we have not yet discussed.  Both simultaneous and relaxed
allow other tasks using the region to execute at the same time and differ
only in what data must be observed.  With simultaneous coherence, a task must 
see all updates to the logical region made by other tasks operating on the same region 
simultaneously (i.e., shared memory semantics).  With relaxed coherence, 
a task may or may not observe updates to the logical region by other tasks executing at
the same time.


\subsubsection{Isolation}

%
%\begin{figure}
%
%\centering
%\begin{tikzpicture}
%\node(top) at (3.5,3.5) { $p$ };
%
%\node(s1) at (1.9,2.5) { $s1$ };
%\node(s2) at (5.1,2.5) { $s2$ };
%
%\node(m1) at (1.9,1.5) { $\ldots$ };
%\node(m2) at (5.1,1.5) { $\ldots$ };
%\node(t1) at (1.9,0.5) { $t_1$ };
%\node(t2) at (5.1,0.5) { $t_2$ };
%
%\draw
%  (top.south) edge (s1.north)
%  (s2.north) edge (top.south)
%  (m1.north) edge (s1.south)
%  (m2.north) edge (s2.south)
%  (t1.north) edge (m1.south)
%  (t2.north) edge (m2.south)
%  ;
%
%\draw[dashed]
%  (t1.east) edge (t2.west)
%  (s1.east) edge (s2.west)
%  ;
%
%\end{tikzpicture}
%\caption{Dependence between tasks implies a dependence between siblings of the least common ancestor.}
%\label{fig:independence}
%\end{figure}

The reader may wonder why we only compare sibling tasks for
dependences: can't arbitrary pairs of tasks have dependences?  The
answer is ``yes'', but the following observation shows why it is sufficient
to check only sibling tasks for dependences.
\begin{observation}
\label{obs:isolation}
\rm
Let $t_1$ and $t_2$ be two sibling tasks with no dependence.  Then no subtask of $t_1$ has a dependence with any subtask
of $t_2$.
\end{observation}
Recall from Section~\ref{sec:ex} that a subtasks can only access subregions of their parent task's region arguments (and with fewer
privileges).  Thus if the regions used by $t_1$ and $t_2$ do not overlap, the regions used by any subtasks of $t_1$ cannot
overlap with the regions used by any subtask of $t_2$.  In the case where the regions used by $t_1$ and $t_2$ do overlap
but there is no dependence because the regions are used with simultaneous or relaxed coherence, then by definition there is no dependence between the subtasks.

\subsubsection{Efficient Dependence Analysis}

Consider the first two subtasks spawned on line 32 of the circuit
simulation in Listing~\ref{lst:code_ex}, {\tt
calc\_new\_currents(pieces[0])} and {\tt
calc\_new\_currents(pieces[1])}.  The first of these tasks reads and
writes the private wires subregion {\tt pieces[0].rw\_pvt} in
exclusive mode, and reads in exclusive mode the node subregions {\tt
pieces[0].rn\_pvt}, {\tt pieces[0].rn\_shr}, and {\tt
pieces[0].rn\_ghost} (see line 39).  The second subtask must be
checked against the first for any dependences; the second subtask uses
{\tt pieces[1].rw\_pvt} (read/write exclusive) and {\tt
pieces[1].rn\_pvt}, {\tt pieces[1].rn\_shr}, and {\tt pieces[1].rn\_ghost} (read-only exclusive).
Recall the region tree in Figure~\ref{sfig:part_fig:tree}.  We reason about the dependences as follows:
\begin{enumerate}
\item {\tt pieces[0].rw\_pvt} and {\tt pieces[1].rw\_pvt} do not overlap as they are subregions of a disjoint partition.
\item {\tt pieces[0].rn\_pvt} and {\tt pieces[1].rn\_pvt} do not overlap for the same reason.
\item {\tt pieces[0].rn\_shr} and {\tt pieces[1].rn\_shr} do not overlap, also for the same reason.
\item {\tt pieces[0].rn\_ghost} may overlap with {\tt pieces[1].rn\_shr}, because they are in two different
  partitions of the same region.
\item {\tt pieces[0].rn\_shr} and {\tt pieces[1].rn\_ghost} may overlap because they are in two different
  partitions of the same region.
\item {\tt pieces[0].rn\_ghost} may overlap with {\tt pieces[1].rn\_ghost} because they are in different subregions of
a non-disjoint, or {\em aliased}, partition.
\item All the remaining pairs of regions used by the two tasks (e.g., {\tt pieces[0].rw\_pvt} and {\tt pieces[1].rn\_pvt})
do not overlap because they are in different region trees and have no common region ancestor.
\end{enumerate}
Cases 4-6 indicate a possible dependence, however in each case the regions are accessed with only read privileges and
so no dependence exists.  Thus, these two subtasks are independent.

A closer look at this example shows that whether there is overlap
between two regions $r_1$ and $r_2$ can be determined by examining
their least common ancestor $\lca{r_1}{r_2}$ in the region tree.  Note
that the region tree alternates between regions and partitions at each
level.  That is, regions are always children of partitions and
partitions are always children of regions in the region tree.  There
are four cases.  If $\lca{r_1}{r_2}$ either does not exist (the regions
are in different region trees) or is a disjoint partition, then $r_1$
and $r_2$ are guaranteed to be disjoint.  If $\lca{r_1}{r_2}$ is an
aliased partition or a region (because $r_1$ and $r_2$ are in
different partitions of the region, as in cases 4 and 5
above), then $r_1$ and $r_2$ may not be disjoint.


To detect dependencies efficiently, the high-level runtime maintains a
local region forest (recall Section~\ref{sec:exec}) for each task.  The
root regions are the task's region arguments, and the forest includes
all partitions and subregions created within the task.  To perform
dependence detection on a region $r$, the runtime first finds a root
region $r'$ such that $r \rleq r'$.  The runtime then walks the region
forest from $r'$ to $r$.  Each region $r''$ on the path contains a
list $L$ of registered tasks using $r''$, and potential dependencies
are discovered by comparing privileges and coherence modes with the
tasks in $L$.

The runtime next checks if a partition of $r''$ is {\em open}.  An
open partition indicates that there are active tasks using subregions
of $r''$.  No more than one partition of a node can be open
at any time.  If the open partition is is along the path to $r$,
traversal continues.  If the open partition lies along another
path the runtime must {\em close} the currently active partition because it cannot guarantee
disjointness with the region the new task wishes to access.  To close a
partition, the runtime finds all active tasks in that
subtree and considers them all dependencies for the new task.
With the previously active partition closed, the runtime can
then open the desired partition and traverse further down the tree as
needed.

When the runtime traverses an open partition, its behavior depends on the kind
of partition being traversed.  If the partition is disjoint, no other subregion
can overlap with the target region, so the state of other subregions is
ignored.  However, if the partition is not disjoint, any
of subregion could overlap with the desired subregion, so
the runtime must close all open subregions (recording new dependencies
as it does so) before continuing the traversal.

After the runtime reaches the target logical region, it performs dependence
checks against any active tasks listed for that region.  If a dependence is
discovered, it is added to the current task's dependence list.  It can then
be removed from the region tree's active task list, as the current task (which
will be pushed onto the active task list) {\em dominates} the previous task.
In a case where the new task has dependencies with all existing active tasks
for the target node, that whole list is replaced by a single entry for the
new task.


\subsection{Distribution}
\label{sec:dist}

\subsection{Mapping}
\label{sec:map}

\subsection{Execution}
\label{sec:exec}

\begin{figure}
\includegraphics[scale=0.48]{figs/CircuitMem.pdf}
\caption{Tasks and data for the circuit simulation on a cluster of GPUs.}
\end{figure}

\subsection{Clean-Up}
\label{sec:clean}

